{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOPpbOm695hhLyGq7+0wlB7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Vocabulary Size X 다양한 머신러닝 모델\n","- Vocabulary Size : 5000, 3000, None\n","- 비교 모델\n","  - MultinomialNB, ComplementNB\n","  - LogisticRegression, LinearSVC\n","  - DecisionTreeClassifier, RandomForestClassifier\n","  - GradientBoostingClassifier\n","  - Voting(soft/hard)  \n","\n"],"metadata":{"id":"YY9tBqUREUiT"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import warnings, os, random\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","import tensorflow as tf\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import layers, models, callbacks\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.naive_bayes import MultinomialNB, ComplementNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report"],"metadata":{"id":"WFxA6XIdEBgi","executionInfo":{"status":"ok","timestamp":1759327645112,"user_tz":-540,"elapsed":9,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["SEED = 0\n","np.random.seed(SEED)\n","\n","# 인덱스 → 단어 복원\n","word_index = reuters.get_word_index()\n","index_to_word = {idx + 3: w for w, idx in word_index.items()}\n","index_to_word[0], index_to_word[1], index_to_word[2] = \"<pad>\", \"<sos>\", \"<unk>\"\n","SPECIALS = {0, 1, 2}\n","\n","# 정수 시퀀스를 공백으로 join한 텍스트로 변환\n","def decode_sequences(seqs, drop_special=True):\n","    out = []\n","    for s in seqs:\n","        toks = []\n","        for t in s:\n","            if drop_special and t in SPECIALS:\n","                continue\n","            toks.append(index_to_word.get(t, \"<unk>\"))\n","        out.append(\" \".join(toks))\n","    return out"],"metadata":{"id":"WSGL1pYKEBeU","executionInfo":{"status":"ok","timestamp":1759327645173,"user_tz":-540,"elapsed":54,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["- 학습 시간 문제로 코드 수정\n","  - Voting - hard 제외, soft만 유지  \n","  - LogisticRegression - max_iter 축소, tol 추가\n","  - RandomForest - n_estimators 축소"],"metadata":{"id":"4SyF1MloHoya"}},{"cell_type":"code","source":["# 모델 파이프라인 정의\n","# - LR, NB, SVM, DT, RF 는 희소 입력 OK → identity\n","# - GB 는 희소 입력 X → densify로 dense 변환 후 적용\n","\n","def build_models(seed=SEED):\n","    identity = FunctionTransformer(lambda X: X, accept_sparse=True)\n","    # densify = FunctionTransformer(lambda X: X.toarray(), accept_sparse=True)\n","\n","    models = {\"NB_Multinomial\": make_pipeline(identity, MultinomialNB()),\n","              \"CNB\": make_pipeline(identity, ComplementNB()),\n","              \"LogReg_L2\": make_pipeline(identity, LogisticRegression(penalty=\"l2\", solver=\"saga\",\n","                                                                      multi_class=\"multinomial\",\n","                                                                      max_iter=1000, tol=1e-3,\n","                                                                      random_state=seed, n_jobs=-1)),\n","              \"LinearSVM\": make_pipeline(identity, LinearSVC(random_state=seed)),\n","              \"DecisionTree\": make_pipeline(identity, DecisionTreeClassifier(random_state=seed)),\n","              \"RandomForest\": make_pipeline(identity, RandomForestClassifier(n_estimators=300,\n","                                                                             random_state=seed,\n","                                                                             n_jobs=-1))}\n","            #   # GradientBoosting은 희소 입력 미지원 → dense 변환\n","            #   \"GradBoost\": make_pipeline(densify, GradientBoostingClassifier(random_state=seed))}\n","\n","    # Voting(soft): 확률 가능한 모델만 (LR, CNB, GB)\n","    voting_soft = VotingClassifier(estimators=[(\"lr\", models[\"LogReg_L2\"]),\n","                                               (\"cnb\", models[\"CNB\"]),\n","                                               (\"nb\", models[\"NB_Multinomial\"])],voting=\"soft\")\n","                                               #(\"gb\", models[\"GradBoost\"])],voting=\"soft\")\n","    # # Voting(hard): 7개 전부\n","    # voting_hard = VotingClassifier(estimators=[(\"nb\", models[\"NB_Multinomial\"]),\n","    #                                            (\"cnb\", models[\"CNB\"]),\n","    #                                            (\"lr\", models[\"LogReg_L2\"]),\n","    #                                            (\"svm\", models[\"LinearSVM\"]),\n","    #                                            (\"dt\", models[\"DecisionTree\"]),\n","    #                                            (\"rf\", models[\"RandomForest\"]),\n","    #                                            (\"gb\", models[\"GradBoost\"])],voting=\"hard\")\n","    return models, voting_soft #,voting_hard"],"metadata":{"id":"4D7Xskc6EBb6","executionInfo":{"status":"ok","timestamp":1759327645178,"user_tz":-540,"elapsed":3,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 학습/평가 함수\n","def eval_model(name, clf, Xtr, ytr, Xte, yte):\n","    clf.fit(Xtr, ytr)\n","    y_pred = clf.predict(Xte)\n","    return {\"model\": name,\n","            \"acc\": accuracy_score(yte, y_pred),\n","            \"balanced_acc\": balanced_accuracy_score(yte, y_pred),\n","            \"macro_f1\": f1_score(yte, y_pred, average=\"macro\"),\n","            \"y_pred\": y_pred}\n","\n","def confusion_summary(y_true, y_pred, topk=10, all_labels=None):\n","    if all_labels is None:\n","        all_labels = np.unique(np.concatenate([y_true, y_pred]))\n","    cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n","    cm_sum = cm.sum(axis=1, keepdims=True)\n","    cm_norm = np.divide(cm, cm_sum, out=np.zeros_like(cm, dtype=float), where=cm_sum!=0)\n","    cm_off = cm_norm.copy()\n","    np.fill_diagonal(cm_off, 0.0)\n","    pairs = np.dstack(np.unravel_index(np.argsort(cm_off.ravel())[::-1], cm_off.shape))[0][:topk]\n","    return cm, cm_norm, pairs, all_labels"],"metadata":{"id":"r7fHFBWHEBZy","executionInfo":{"status":"ok","timestamp":1759327645191,"user_tz":-540,"elapsed":10,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 실행 함수(num_words, vec_mode만 바꿔 호출)\n","def run_once(num_words, vec_mode=\"tfidf\", topk_pairs=10, seed=SEED):\n","    # 데이터 로드\n","    (xtr_ids, ytr), (xte_ids, yte) = reuters.load_data(num_words=num_words, test_split=0.2)\n","\n","    # 텍스트 복원\n","    xtr_text = decode_sequences(xtr_ids, drop_special=True)\n","    xte_text = decode_sequences(xte_ids, drop_special=True)\n","\n","    # 벡터화\n","    if vec_mode == \"tfidf\":\n","        vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=2, max_df=0.95, sublinear_tf=True)\n","    else:\n","        vectorizer = CountVectorizer(ngram_range=(1,1), min_df=2, max_df=0.95)\n","\n","    Xtr = vectorizer.fit_transform(xtr_text)\n","    Xte = vectorizer.transform(xte_text)\n","\n","    # 모델 구성\n","    # models, voting_soft, voting_hard = build_models(seed=seed)\n","    models, voting_soft = build_models(seed=seed)\n","\n","    # 학습 & 평가\n","    results = []\n","    for name, clf in models.items():\n","        results.append(eval_model(name, clf, Xtr, ytr, Xte, yte))\n","    results.append(eval_model(\"Voting_soft(LR+CNB+NB)\", voting_soft, Xtr, ytr, Xte, yte))\n","    # results.append(eval_model(\"Voting_hard(All)\", voting_hard, Xtr, ytr, Xte, yte))\n","\n","    # 요약 표 출력\n","    df_res = (pd.DataFrame(results)\n","              .sort_values(\"macro_f1\", ascending=False).reset_index(drop=True))\n","\n","    print(f\"[num_words={num_words} | vec={vec_mode}] 결과 (Macro-F1 기준 내림차순)\")\n","    print(df_res[[\"model\", \"acc\", \"balanced_acc\", \"macro_f1\"]].to_string(index=False))\n","\n","    # 혼동행렬 요약 (베스트 1개)\n","    best = max(results, key=lambda d: d[\"macro_f1\"])\n","    cm, cm_norm, pairs, labels = confusion_summary(yte, best[\"y_pred\"], topk=topk_pairs)\n","\n","    print(f\"\\n[Best by macro-F1] {best['model']}의 혼동행렬 요약\")\n","    print(f\"- Confusion matrix shape: {cm.shape} (rows=true, cols=predicted)\")\n","    print(f\"\\nTop-{topk_pairs} confused pairs (true -> pred: rate, count):\")\n","\n","    for i, j in pairs:\n","        count = cm[i, j]\n","        if count > 0:\n","            print(f\"  {labels[i]} -> {labels[j]}: rate={cm_norm[i, j]:.3f}, count={count}\")\n","\n","    return df_res, results, (cm, cm_norm, labels)"],"metadata":{"id":"3wdt7nZ5EBXq","executionInfo":{"status":"ok","timestamp":1759327645198,"user_tz":-540,"elapsed":5,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# num_words=5000\n","df_5000, results_5000, cm_pack_5000 = run_once(num_words=5000, vec_mode=\"tfidf\", topk_pairs=10, seed=SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7CLgCSzEBVq","executionInfo":{"status":"ok","timestamp":1759327675265,"user_tz":-540,"elapsed":30062,"user":{"displayName":"정주이","userId":"02044851678225674035"}},"outputId":"c825524a-a78d-4571-a612-abef4eac805e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[num_words=5000 | vec=tfidf] 결과 (Macro-F1 기준 내림차순)\n","                 model      acc  balanced_acc  macro_f1\n","             LinearSVM 0.832146      0.634498  0.675920\n","          RandomForest 0.773375      0.418554  0.473705\n","          DecisionTree 0.703473      0.445195  0.447408\n","                   CNB 0.763580      0.404732  0.441942\n","             LogReg_L2 0.798753      0.394181  0.432609\n","Voting_soft(LR+CNB+GB) 0.732413      0.217712  0.247759\n","        NB_Multinomial 0.678094      0.122976  0.113883\n","\n","[Best by macro-F1] LinearSVM의 혼동행렬 요약\n","- Confusion matrix shape: (46, 46) (rows=true, cols=predicted)\n","\n","Top-10 confused pairs (true -> pred: rate, count):\n","  5 -> 1: rate=1.000, count=5\n","  40 -> 19: rate=0.700, count=7\n","  42 -> 25: rate=0.667, count=2\n","  37 -> 4: rate=0.500, count=1\n","  41 -> 4: rate=0.500, count=4\n","  14 -> 11: rate=0.500, count=1\n","  36 -> 11: rate=0.455, count=5\n","  15 -> 28: rate=0.444, count=4\n","  38 -> 1: rate=0.333, count=1\n","  35 -> 11: rate=0.333, count=2\n"]}]},{"cell_type":"code","source":["# num_words=3000\n","df_3000, results_3000, cm_pack_3000 = run_once(num_words=3000, vec_mode=\"tfidf\", topk_pairs=10, seed=SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJ7NCnIYEBTS","executionInfo":{"status":"ok","timestamp":1759327701461,"user_tz":-540,"elapsed":26184,"user":{"displayName":"정주이","userId":"02044851678225674035"}},"outputId":"d2d64f15-c131-4db9-ad8e-3abc4340f80c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[num_words=3000 | vec=tfidf] 결과 (Macro-F1 기준 내림차순)\n","                 model      acc  balanced_acc  macro_f1\n","             LinearSVM 0.834372      0.637980  0.682639\n","          RandomForest 0.782725      0.442724  0.491461\n","             LogReg_L2 0.802760      0.423390  0.467768\n","          DecisionTree 0.695459      0.452602  0.448998\n","                   CNB 0.756901      0.404111  0.438829\n","Voting_soft(LR+CNB+GB) 0.750223      0.268574  0.298092\n","        NB_Multinomial 0.695013      0.157038  0.163511\n","\n","[Best by macro-F1] LinearSVM의 혼동행렬 요약\n","- Confusion matrix shape: (46, 46) (rows=true, cols=predicted)\n","\n","Top-10 confused pairs (true -> pred: rate, count):\n","  5 -> 1: rate=1.000, count=5\n","  40 -> 19: rate=0.700, count=7\n","  41 -> 4: rate=0.500, count=4\n","  14 -> 11: rate=0.500, count=1\n","  37 -> 4: rate=0.500, count=1\n","  36 -> 11: rate=0.455, count=5\n","  15 -> 28: rate=0.333, count=3\n","  38 -> 1: rate=0.333, count=1\n","  38 -> 16: rate=0.333, count=1\n","  35 -> 11: rate=0.333, count=2\n"]}]},{"cell_type":"code","source":["# num_words=None\n","df_None, results_None, cm_pack_None = run_once(num_words=None, vec_mode=\"tfidf\", topk_pairs=10, seed=SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iskw8mcNEBQ1","executionInfo":{"status":"ok","timestamp":1759327746543,"user_tz":-540,"elapsed":45079,"user":{"displayName":"정주이","userId":"02044851678225674035"}},"outputId":"b3b36163-7152-4aff-864e-3b78f42200a7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[num_words=None | vec=tfidf] 결과 (Macro-F1 기준 내림차순)\n","                 model      acc  balanced_acc  macro_f1\n","             LinearSVM 0.831256      0.631417  0.667421\n","          DecisionTree 0.707035      0.471876  0.461522\n","                   CNB 0.758682      0.408033  0.454552\n","          RandomForest 0.761799      0.390794  0.447817\n","             LogReg_L2 0.788958      0.340861  0.373389\n","Voting_soft(LR+CNB+GB) 0.684773      0.137222  0.155720\n","        NB_Multinomial 0.632235      0.086281  0.084486\n","\n","[Best by macro-F1] LinearSVM의 혼동행렬 요약\n","- Confusion matrix shape: (46, 46) (rows=true, cols=predicted)\n","\n","Top-10 confused pairs (true -> pred: rate, count):\n","  5 -> 1: rate=1.000, count=5\n","  42 -> 25: rate=0.667, count=2\n","  40 -> 19: rate=0.600, count=6\n","  37 -> 4: rate=0.500, count=1\n","  41 -> 4: rate=0.500, count=4\n","  14 -> 11: rate=0.500, count=1\n","  36 -> 11: rate=0.455, count=5\n","  15 -> 28: rate=0.444, count=4\n","  17 -> 16: rate=0.417, count=5\n","  35 -> 11: rate=0.333, count=2\n"]}]},{"cell_type":"markdown","source":["- 모델 비교\n","  - LinearSVM\n","    - 고차원 희소 벡터(BoW/TF-IDF)에 강한 선형 분류기\n","    - accuracy(0.83±) 대비 balanced_acc(0.63±)·macro-F1(0.67~0.68) 간 격차는 클래스 불균형 탓. 다수 클래스는 잘 맞추지만 소수 클래스 리콜은 떨어진다는 신호\n","  - LogisticRegression\n","    - 정확도는 준수(0.79~0.80)하지만 macro-F1은 SVM보다 낮음\n","      - 동일한 선형 계열이라도 정규화/최적화 차이와 다중클래스 로스(softmax)의 특성상 소수 클래스에서 결정경계가 조금 더 보수적으로 형성되기 쉬움\n","      - 기본 임계값(0.5 argmax)로는 소수 클래스 리콜을 끌어올리기 어려움 → class_weight='balanced', C 튜닝으로 개선 여지\n","  - Naive Bayes (Multinomial/Complement)\n","    - 빠르고 투박: 다수 클래스에 유리, 소수 클래스 리콜이 낮아 macro-F1이 낮음\n","    - ComplementNB가 MultinomialNB보다 일반적으로 불균형에 더 강함\n","  - RandomForest / DecisionTree\n","    - 희소·고차원에서 트리 분기는 정보이득이 분산되어 성능/균형 정확도 낮음(macro-F1 0.44~0.49)\n","    - RF가 DT보다 낫지만 여전히 선형 모델 대비 불리\n","  - Voting_soft\n","    - LR+CNB+NB라서 약한 NB 2개 + LR 1개 조합이 되어 LR 단독보다 못함\n","    - 확률교정/가중치 부재: LR만 강하고 NB는 약하니 평균하면 신호가 희석\n","\n","- 단어 수(num_words)에 따른 경향\n","  - 3000 > 5000 ≥ None (macro-F1 기준)\n","    - 3000: 희소성과 노이즈의 균형이 가장 좋음 → 최고 macro-F1(0.6826)\n","    - 5000: 약간의 노이즈 증가로 소수 클래스 리콜이 아주 약간 희생\n","    - None(전체): 희귀 토큰 과다 → 분산 증가, 소수 클래스에서 오히려 성능 하락\n","\n","- 혼동행렬 Top-10\n","  - 공통적으로 5→1, 40→19, 41→4, 36→11, 15→28 등이 자주 등장\n","    - 테스트 표본 수가 적거나, 어휘가 유사해 결정경계가 잘 안 갈라질 가능성이 높음"],"metadata":{"id":"Qi5LwMk_JMqM"}},{"cell_type":"markdown","source":["## Vocabulary Size X 딥러닝 모델\n","- Vocabulary Size : 5000, 3000, None\n","- 비교 모델  : cnn, bilstm"],"metadata":{"id":"USkYzfDhD3Tm"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"mEX0o6PMDzDN","executionInfo":{"status":"ok","timestamp":1759327746550,"user_tz":-540,"elapsed":2,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import warnings, os, random\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","import tensorflow as tf\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import layers, models, callbacks\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.naive_bayes import MultinomialNB, ComplementNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report"]},{"cell_type":"code","source":["SEED = 42\n","EPOCHS = 12\n","BATCH_SIZE = 128\n","EMBED_DIM = 128\n","\n","NUM_WORDS_LIST = [3000, 5000, 10000]\n","USE_MODELS = [\"cnn\", \"bilstm\"]\n","MAXLEN_LIST = [200, 300, 500]\n","\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"],"metadata":{"id":"tqueAn-2D-3e","executionInfo":{"status":"ok","timestamp":1759327746571,"user_tz":-540,"elapsed":6,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# DL models\n","def build_cnn(vocab_size, maxlen, embed_dim=128, filters=128, ksz=5, dp=0.3, classes=46):\n","    inp = layers.Input(shape=(maxlen,), dtype=\"int32\")\n","    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(inp)\n","    x = layers.Conv1D(filters, ksz, padding=\"same\", activation=\"relu\")(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","    x = layers.Dropout(dp)(x)\n","    x = layers.Dense(128, activation=\"relu\")(x)\n","    out = layers.Dense(classes, activation=\"softmax\")(x)\n","    model = models.Model(inp, out)\n","    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","    return model\n","\n","def build_bilstm(vocab_size, maxlen, embed_dim=128, units=64, dp=0.3, classes=46):\n","    inp = layers.Input(shape=(maxlen,), dtype=\"int32\")\n","    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(inp)\n","    x = layers.Bidirectional(layers.LSTM(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","    x = layers.Dropout(dp)(x)\n","    x = layers.Dense(128, activation=\"relu\")(x)\n","    out = layers.Dense(classes, activation=\"softmax\")(x)\n","    model = models.Model(inp, out)\n","    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","    return model"],"metadata":{"id":"Ib-OHl_lD-51","executionInfo":{"status":"ok","timestamp":1759327746583,"user_tz":-540,"elapsed":10,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 인덱스 → 단어 복원\n","word_index = reuters.get_word_index()\n","index_to_word = {idx + 3: w for w, idx in word_index.items()}\n","index_to_word[0], index_to_word[1], index_to_word[2] = \"<pad>\", \"<sos>\", \"<unk>\"\n","SPECIALS = {0, 1, 2}\n","\n","def decode_sequences(seqs, drop_special=True):\n","    out = []\n","    for s in seqs:\n","        toks = [index_to_word.get(t, \"<unk>\") for t in s if (not drop_special or t not in SPECIALS)]\n","        out.append(\" \".join(toks))\n","    return out\n","\n","def run_one(num_words, use_model, maxlen):\n","    # Load data\n","    (xtr_ids, ytr), (xte_ids, yte) = reuters.load_data(num_words=num_words, test_split=0.2)\n","\n","    # Pad for DL models\n","    Xtr_seq = pad_sequences(xtr_ids, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n","    Xte_seq = pad_sequences(xte_ids,  maxlen=maxlen, padding=\"post\", truncating=\"post\")\n","\n","    # vocab_size (Embedding 용)\n","    max_index = 0\n","    for s in list(xtr_ids) + list(xte_ids):\n","        if len(s): max_index = max(max_index, max(s))\n","    vocab_size = max_index + 1\n","    n_classes = int(max(max(ytr), max(yte)) + 1)\n","\n","    # DL 모델 선택/학습\n","    if use_model == \"cnn\":\n","        dl_model = build_cnn(vocab_size, maxlen, EMBED_DIM, classes=n_classes)\n","    elif use_model == \"bilstm\":\n","        dl_model = build_bilstm(vocab_size, maxlen, EMBED_DIM, classes=n_classes)\n","    else:\n","        raise ValueError(\"USE_MODEL must be 'cnn' or 'bilstm'.\")\n","\n","    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2, restore_best_weights=True)\n","    rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, min_lr=1e-5)\n","\n","    dl_model.fit(Xtr_seq, ytr, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE,\n","                 callbacks=[es, rlr], verbose=0)\n","\n","    y_prob_dl = dl_model.predict(Xte_seq, verbose=0)\n","    y_pred_dl = np.argmax(y_prob_dl, axis=1)\n","    acc_dl  = accuracy_score(yte, y_pred_dl)\n","    bacc_dl = balanced_accuracy_score(yte, y_pred_dl)\n","    f1m_dl  = f1_score(yte, y_pred_dl, average=\"macro\")\n","\n","    print(\"\\n[classification_report] (DL)\")\n","    print(classification_report(yte, y_pred_dl, digits=4, zero_division=0))\n","\n","    # Classical baseline: TF-IDF + Logistic Regression (동일 num_words의 텍스트)\n","    xtr_text = decode_sequences(xtr_ids, drop_special=True)\n","    xte_text = decode_sequences(xte_ids,  drop_special=True)\n","\n","    tfidf = TfidfVectorizer(ngram_range=(1,1), min_df=2, max_df=0.95, sublinear_tf=True)\n","    Xtr_tfidf = tfidf.fit_transform(xtr_text)\n","    Xte_tfidf = tfidf.transform(xte_text)\n","\n","    lr = LogisticRegression(penalty=\"l2\", solver=\"saga\", max_iter=2000, random_state=SEED)\n","    lr.fit(Xtr_tfidf, ytr)\n","    y_pred_lr = lr.predict(Xte_tfidf)\n","\n","    acc_lr  = accuracy_score(yte, y_pred_lr)\n","    bacc_lr = balanced_accuracy_score(yte, y_pred_lr)\n","    f1m_lr  = f1_score(yte, y_pred_lr, average=\"macro\")\n","\n","    print(\"\\n[classification_report] (TFIDF+LR)\")\n","    print(classification_report(yte, y_pred_lr, digits=4, zero_division=0))\n","\n","    return {\"num_words\": num_words, \"use_model\": use_model, \"maxlen\": maxlen, \"dl_acc\": acc_dl,\n","            \"dl_bal_acc\": bacc_dl, \"dl_macro_f1\": f1m_dl, \"lr_acc\": acc_lr, \"lr_bal_acc\": bacc_lr,\n","            \"lr_macro_f1\": f1m_lr, \"delta_macro_f1\": f1m_dl - f1m_lr}"],"metadata":{"id":"56Qk-LA-D-8H","executionInfo":{"status":"ok","timestamp":1759327746597,"user_tz":-540,"elapsed":12,"user":{"displayName":"정주이","userId":"02044851678225674035"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["rows = []\n","for nw in NUM_WORDS_LIST:\n","    for um in USE_MODELS:\n","        for ml in MAXLEN_LIST:\n","            print(f\"Running: num_words={nw}, use_model={um}, maxlen={ml} ...\")\n","            rows.append(run_one(nw, um, ml))\n","\n","df = pd.DataFrame(rows).sort_values([\"dl_macro_f1\",\"lr_macro_f1\"], ascending=False).reset_index(drop=True)\n","\n","cols = [\"num_words\",\"use_model\",\"maxlen\", \"dl_acc\",\"dl_bal_acc\",\"dl_macro_f1\",\n","        \"lr_acc\",\"lr_bal_acc\",\"lr_macro_f1\", \"delta_macro_f1\"]\n","print(\"\\n===== Summary (DL vs TFIDF+LR) =====\")\n","print(df[cols].to_string(index=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7pEixObTD--g","executionInfo":{"status":"error","timestamp":1759329064516,"user_tz":-540,"elapsed":1317917,"user":{"displayName":"정주이","userId":"02044851678225674035"}},"outputId":"869f1216-4593-4f3a-cb92-fb3b9ffa7bc1"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Running: num_words=None, use_model=cnn, maxlen=200 ...\n","\n","[classification_report] (DL)\n","              precision    recall  f1-score   support\n","\n","           0     0.8889    0.6667    0.7619        12\n","           1     0.7692    0.8571    0.8108       105\n","           2     0.5600    0.7000    0.6222        20\n","           3     0.9310    0.9459    0.9384       813\n","           4     0.8178    0.8903    0.8525       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     0.5882    0.7143    0.6452        14\n","           7     1.0000    0.3333    0.5000         3\n","           8     0.6923    0.7105    0.7013        38\n","           9     0.7857    0.8800    0.8302        25\n","          10     0.9062    0.9667    0.9355        30\n","          11     0.5963    0.7831    0.6771        83\n","          12     0.6667    0.1538    0.2500        13\n","          13     0.5682    0.6757    0.6173        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.7308    0.7677    0.7488        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.4783    0.5500    0.5116        20\n","          19     0.6266    0.7444    0.6804       133\n","          20     0.6364    0.5000    0.5600        70\n","          21     0.6562    0.7778    0.7119        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.4444    0.3333    0.3810        12\n","          24     0.4211    0.4211    0.4211        19\n","          25     0.7391    0.5484    0.6296        31\n","          26     0.8571    0.7500    0.8000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     0.6000    0.3000    0.4000        10\n","          29     1.0000    0.2500    0.4000         4\n","          30     0.5000    0.3333    0.4000        12\n","          31     1.0000    0.2308    0.3750        13\n","          32     1.0000    1.0000    1.0000        10\n","          33     1.0000    0.2000    0.3333         5\n","          34     0.4286    0.4286    0.4286         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     0.5000    0.2727    0.3529        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     1.0000    0.3333    0.5000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     1.0000    0.1667    0.2857         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7992      2246\n","   macro avg     0.5302    0.4127    0.4337      2246\n","weighted avg     0.7782    0.7992    0.7815      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","[classification_report] (TFIDF+LR)\n","              precision    recall  f1-score   support\n","\n","           0     0.8571    0.5000    0.6316        12\n","           1     0.6170    0.8286    0.7073       105\n","           2     0.8333    0.5000    0.6250        20\n","           3     0.9192    0.9373    0.9281       813\n","           4     0.7329    0.9262    0.8183       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     1.0000    0.7143    0.8333        14\n","           7     1.0000    0.3333    0.5000         3\n","           8     0.6857    0.6316    0.6575        38\n","           9     0.9545    0.8400    0.8936        25\n","          10     0.9615    0.8333    0.8929        30\n","          11     0.5812    0.8193    0.6800        83\n","          12     1.0000    0.0769    0.1429        13\n","          13     0.7059    0.6486    0.6761        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6290    0.7879    0.6996        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.6667    0.6000    0.6316        20\n","          19     0.6939    0.7669    0.7286       133\n","          20     0.8000    0.5143    0.6261        70\n","          21     0.7037    0.7037    0.7037        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.5000    0.0833    0.1429        12\n","          24     1.0000    0.1579    0.2727        19\n","          25     0.9130    0.6774    0.7778        31\n","          26     0.0000    0.0000    0.0000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     1.0000    0.1000    0.1818        10\n","          29     0.0000    0.0000    0.0000         4\n","          30     0.7500    0.2500    0.3750        12\n","          31     1.0000    0.0769    0.1429        13\n","          32     1.0000    0.6000    0.7500        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     1.0000    0.7143    0.8333         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     1.0000    0.0909    0.1667        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     0.0000    0.0000    0.0000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     1.0000    0.1667    0.2857         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7890      2246\n","   macro avg     0.5327    0.3409    0.3738      2246\n","weighted avg     0.7733    0.7890    0.7611      2246\n","\n","Running: num_words=None, use_model=cnn, maxlen=300 ...\n","\n","[classification_report] (DL)\n","              precision    recall  f1-score   support\n","\n","           0     0.8000    0.6667    0.7273        12\n","           1     0.7288    0.8190    0.7713       105\n","           2     0.7143    0.7500    0.7317        20\n","           3     0.9217    0.9410    0.9312       813\n","           4     0.8381    0.8734    0.8554       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     1.0000    0.9286    0.9630        14\n","           7     0.6667    0.6667    0.6667         3\n","           8     0.6429    0.7105    0.6750        38\n","           9     0.9167    0.8800    0.8980        25\n","          10     0.9062    0.9667    0.9355        30\n","          11     0.6556    0.7108    0.6821        83\n","          12     0.6667    0.1538    0.2500        13\n","          13     0.5385    0.5676    0.5526        37\n","          14     0.5000    0.5000    0.5000         2\n","          15     0.2857    0.2222    0.2500         9\n","          16     0.6500    0.7879    0.7123        99\n","          17     1.0000    0.1667    0.2857        12\n","          18     0.7500    0.6000    0.6667        20\n","          19     0.6012    0.7368    0.6622       133\n","          20     0.6271    0.5286    0.5736        70\n","          21     0.6562    0.7778    0.7119        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.3333    0.1667    0.2222        12\n","          24     0.4444    0.4211    0.4324        19\n","          25     0.7931    0.7419    0.7667        31\n","          26     0.5000    0.2500    0.3333         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     0.4444    0.4000    0.4211        10\n","          29     0.3333    0.2500    0.2857         4\n","          30     0.8333    0.4167    0.5556        12\n","          31     0.7143    0.3846    0.5000        13\n","          32     0.8182    0.9000    0.8571        10\n","          33     1.0000    0.6000    0.7500         5\n","          34     1.0000    0.5714    0.7273         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     0.7500    0.5455    0.6316        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     1.0000    0.3333    0.5000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     1.0000    0.2000    0.3333        10\n","          41     0.5000    0.1250    0.2000         8\n","          42     1.0000    0.3333    0.5000         3\n","          43     0.5714    0.6667    0.6154         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.8010      2246\n","   macro avg     0.6109    0.4796    0.5114      2246\n","weighted avg     0.7925    0.8010    0.7894      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","[classification_report] (TFIDF+LR)\n","              precision    recall  f1-score   support\n","\n","           0     0.8571    0.5000    0.6316        12\n","           1     0.6170    0.8286    0.7073       105\n","           2     0.8333    0.5000    0.6250        20\n","           3     0.9192    0.9373    0.9281       813\n","           4     0.7329    0.9262    0.8183       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     1.0000    0.7143    0.8333        14\n","           7     1.0000    0.3333    0.5000         3\n","           8     0.6857    0.6316    0.6575        38\n","           9     0.9545    0.8400    0.8936        25\n","          10     0.9615    0.8333    0.8929        30\n","          11     0.5812    0.8193    0.6800        83\n","          12     1.0000    0.0769    0.1429        13\n","          13     0.7059    0.6486    0.6761        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6290    0.7879    0.6996        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.6667    0.6000    0.6316        20\n","          19     0.6939    0.7669    0.7286       133\n","          20     0.8000    0.5143    0.6261        70\n","          21     0.7037    0.7037    0.7037        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.5000    0.0833    0.1429        12\n","          24     1.0000    0.1579    0.2727        19\n","          25     0.9130    0.6774    0.7778        31\n","          26     0.0000    0.0000    0.0000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     1.0000    0.1000    0.1818        10\n","          29     0.0000    0.0000    0.0000         4\n","          30     0.7500    0.2500    0.3750        12\n","          31     1.0000    0.0769    0.1429        13\n","          32     1.0000    0.6000    0.7500        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     1.0000    0.7143    0.8333         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     1.0000    0.0909    0.1667        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     0.0000    0.0000    0.0000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     1.0000    0.1667    0.2857         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7890      2246\n","   macro avg     0.5327    0.3409    0.3738      2246\n","weighted avg     0.7733    0.7890    0.7611      2246\n","\n","Running: num_words=None, use_model=cnn, maxlen=500 ...\n","\n","[classification_report] (DL)\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    0.5833    0.7000        12\n","           1     0.7458    0.8381    0.7892       105\n","           2     0.6667    0.7000    0.6829        20\n","           3     0.9228    0.9410    0.9318       813\n","           4     0.8303    0.8776    0.8533       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     0.9167    0.7857    0.8462        14\n","           7     1.0000    0.6667    0.8000         3\n","           8     0.6136    0.7105    0.6585        38\n","           9     0.8462    0.8800    0.8627        25\n","          10     0.9062    0.9667    0.9355        30\n","          11     0.6702    0.7590    0.7119        83\n","          12     0.7500    0.2308    0.3529        13\n","          13     0.4231    0.5946    0.4944        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6446    0.7879    0.7091        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.5000    0.6000    0.5455        20\n","          19     0.6125    0.7368    0.6689       133\n","          20     0.6531    0.4571    0.5378        70\n","          21     0.5676    0.7778    0.6562        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.4000    0.1667    0.2353        12\n","          24     0.5333    0.4211    0.4706        19\n","          25     0.5806    0.5806    0.5806        31\n","          26     1.0000    0.8750    0.9333         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     0.1429    0.1000    0.1176        10\n","          29     0.6667    0.5000    0.5714         4\n","          30     0.5556    0.4167    0.4762        12\n","          31     0.8000    0.3077    0.4444        13\n","          32     1.0000    0.9000    0.9474        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     1.0000    0.2857    0.4444         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     0.6000    0.2727    0.3750        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     1.0000    0.3333    0.5000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     1.0000    0.1000    0.1818        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     1.0000    0.3333    0.5000         3\n","          43     0.5000    0.1667    0.2500         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     1.0000    1.0000    1.0000         1\n","\n","    accuracy                         0.7925      2246\n","   macro avg     0.5636    0.4446    0.4707      2246\n","weighted avg     0.7754    0.7925    0.7765      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","[classification_report] (TFIDF+LR)\n","              precision    recall  f1-score   support\n","\n","           0     0.8571    0.5000    0.6316        12\n","           1     0.6170    0.8286    0.7073       105\n","           2     0.8333    0.5000    0.6250        20\n","           3     0.9192    0.9373    0.9281       813\n","           4     0.7329    0.9262    0.8183       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     1.0000    0.7143    0.8333        14\n","           7     1.0000    0.3333    0.5000         3\n","           8     0.6857    0.6316    0.6575        38\n","           9     0.9545    0.8400    0.8936        25\n","          10     0.9615    0.8333    0.8929        30\n","          11     0.5812    0.8193    0.6800        83\n","          12     1.0000    0.0769    0.1429        13\n","          13     0.7059    0.6486    0.6761        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6290    0.7879    0.6996        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.6667    0.6000    0.6316        20\n","          19     0.6939    0.7669    0.7286       133\n","          20     0.8000    0.5143    0.6261        70\n","          21     0.7037    0.7037    0.7037        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.5000    0.0833    0.1429        12\n","          24     1.0000    0.1579    0.2727        19\n","          25     0.9130    0.6774    0.7778        31\n","          26     0.0000    0.0000    0.0000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     1.0000    0.1000    0.1818        10\n","          29     0.0000    0.0000    0.0000         4\n","          30     0.7500    0.2500    0.3750        12\n","          31     1.0000    0.0769    0.1429        13\n","          32     1.0000    0.6000    0.7500        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     1.0000    0.7143    0.8333         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     1.0000    0.0909    0.1667        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     0.0000    0.0000    0.0000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     1.0000    0.1667    0.2857         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7890      2246\n","   macro avg     0.5327    0.3409    0.3738      2246\n","weighted avg     0.7733    0.7890    0.7611      2246\n","\n","Running: num_words=None, use_model=bilstm, maxlen=200 ...\n","\n","[classification_report] (DL)\n","              precision    recall  f1-score   support\n","\n","           0     0.6667    0.1667    0.2667        12\n","           1     0.7456    0.8095    0.7763       105\n","           2     0.4412    0.7500    0.5556        20\n","           3     0.9171    0.9520    0.9342       813\n","           4     0.8589    0.8608    0.8599       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     0.3077    0.2857    0.2963        14\n","           7     0.0000    0.0000    0.0000         3\n","           8     0.5952    0.6579    0.6250        38\n","           9     0.5385    0.8400    0.6562        25\n","          10     0.7941    0.9000    0.8438        30\n","          11     0.5528    0.8193    0.6602        83\n","          12     0.0000    0.0000    0.0000        13\n","          13     0.3750    0.4054    0.3896        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6094    0.7879    0.6872        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.4231    0.5500    0.4783        20\n","          19     0.6849    0.7519    0.7168       133\n","          20     0.6200    0.4429    0.5167        70\n","          21     0.2909    0.5926    0.3902        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.0000    0.0000    0.0000        12\n","          24     0.3333    0.3158    0.3243        19\n","          25     0.3913    0.5806    0.4675        31\n","          26     0.0000    0.0000    0.0000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     0.2500    0.1000    0.1429        10\n","          29     0.0000    0.0000    0.0000         4\n","          30     0.0000    0.0000    0.0000        12\n","          31     0.0000    0.0000    0.0000        13\n","          32     1.0000    0.1000    0.1818        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     0.7143    0.7143    0.7143         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     0.0000    0.0000    0.0000        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     0.0000    0.0000    0.0000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     0.0000    0.0000    0.0000         6\n","          44     0.0000    0.0000    0.0000         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7618      2246\n","   macro avg     0.2633    0.2692    0.2496      2246\n","weighted avg     0.7208    0.7618    0.7348      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","[classification_report] (TFIDF+LR)\n","              precision    recall  f1-score   support\n","\n","           0     0.8571    0.5000    0.6316        12\n","           1     0.6170    0.8286    0.7073       105\n","           2     0.8333    0.5000    0.6250        20\n","           3     0.9192    0.9373    0.9281       813\n","           4     0.7329    0.9262    0.8183       474\n","           5     0.0000    0.0000    0.0000         5\n","           6     1.0000    0.7143    0.8333        14\n","           7     1.0000    0.3333    0.5000         3\n","           8     0.6857    0.6316    0.6575        38\n","           9     0.9545    0.8400    0.8936        25\n","          10     0.9615    0.8333    0.8929        30\n","          11     0.5812    0.8193    0.6800        83\n","          12     1.0000    0.0769    0.1429        13\n","          13     0.7059    0.6486    0.6761        37\n","          14     0.0000    0.0000    0.0000         2\n","          15     0.0000    0.0000    0.0000         9\n","          16     0.6290    0.7879    0.6996        99\n","          17     0.0000    0.0000    0.0000        12\n","          18     0.6667    0.6000    0.6316        20\n","          19     0.6939    0.7669    0.7286       133\n","          20     0.8000    0.5143    0.6261        70\n","          21     0.7037    0.7037    0.7037        27\n","          22     0.0000    0.0000    0.0000         7\n","          23     0.5000    0.0833    0.1429        12\n","          24     1.0000    0.1579    0.2727        19\n","          25     0.9130    0.6774    0.7778        31\n","          26     0.0000    0.0000    0.0000         8\n","          27     0.0000    0.0000    0.0000         4\n","          28     1.0000    0.1000    0.1818        10\n","          29     0.0000    0.0000    0.0000         4\n","          30     0.7500    0.2500    0.3750        12\n","          31     1.0000    0.0769    0.1429        13\n","          32     1.0000    0.6000    0.7500        10\n","          33     0.0000    0.0000    0.0000         5\n","          34     1.0000    0.7143    0.8333         7\n","          35     0.0000    0.0000    0.0000         6\n","          36     1.0000    0.0909    0.1667        11\n","          37     0.0000    0.0000    0.0000         2\n","          38     0.0000    0.0000    0.0000         3\n","          39     0.0000    0.0000    0.0000         5\n","          40     0.0000    0.0000    0.0000        10\n","          41     0.0000    0.0000    0.0000         8\n","          42     0.0000    0.0000    0.0000         3\n","          43     1.0000    0.1667    0.2857         6\n","          44     1.0000    0.8000    0.8889         5\n","          45     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.7890      2246\n","   macro avg     0.5327    0.3409    0.3738      2246\n","weighted avg     0.7733    0.7890    0.7611      2246\n","\n","Running: num_words=None, use_model=bilstm, maxlen=300 ...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-958799322.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMAXLEN_LIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running: num_words={nw}, use_model={um}, maxlen={ml} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dl_macro_f1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lr_macro_f1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2696097374.py\u001b[0m in \u001b[0;36mrun_one\u001b[0;34m(num_words, use_model, maxlen)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     dl_model.fit(Xtr_seq, ytr, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE,\n\u001b[0m\u001b[1;32m     41\u001b[0m                  callbacks=[es, rlr], verbose=0)\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}