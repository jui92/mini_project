# -*- coding: utf-8 -*-
# interview_coach_bot_2.py
# -----------------------------------------------------------
# ë³€ê²½ ìš”ì•½
# - ì´ì  ì¼ì›í™”: ì—­ëŸ‰ 5ì¶•(0~20)ì˜ í‰ê· Ã—5 â†’ 0~100ìœ¼ë¡œ ì‚°ì¶œí•˜ì—¬
#   ìš°ì¸¡ í”¼ë“œë°± ë³¸ë¬¸ ì²« ì¤„ 'ì´ì :'ì„ ê°•ì œ ì¹˜í™˜(ì¢Œ/ìš° í•­ìƒ ë™ì¼)
# - ë ˆì´ë” í‘œ: 'í•©ê³„'(5ì¶• í•©, 0~100) ì»¬ëŸ¼ ì¶”ê°€ + ê°’ ë³´ì •(0~20)
# - ì†ë„ ê°œì„ : ì„ë² ë”© ìºì‹œ(@st.cache_data), ì§ˆë¬¸/ë‹µë³€ í† í° ë‹¤ì´ì–´íŠ¸
# - ì•± êµ¬ì¡°: íšŒì‚¬/ì§ë¬´ ì…ë ¥ â†’ (ì„ íƒ)RAG ì¸ë±ì‹± â†’ ì§ˆë¬¸ ìƒì„± â†’ ì±„ì /ì½”ì¹­ â†’ ì‹œê°í™”/CSV
# -----------------------------------------------------------

import os, re, io, difflib, random, textwrap
from typing import List, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st

# Optional: Plotly(ë ˆì´ë” ê·¸ë˜í”„), ì—†ìœ¼ë©´ bar ì°¨íŠ¸ë¡œ ëŒ€ì²´
try:
    import plotly.graph_objects as go
    PLOTLY_OK = True
except Exception:
    PLOTLY_OK = False

# OpenAI SDK
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# -----------------------------
# í˜ì´ì§€ ì„¤ì •
# -----------------------------
st.set_page_config(page_title="íšŒì‚¬ íŠ¹í™” ëª¨ì˜ ë©´ì ‘ ì½”ì¹˜", page_icon="ğŸ¯", layout="wide")

# -----------------------------
# Key ë¡œë”©
# -----------------------------
def load_api_key() -> Optional[str]:
    k = os.getenv("OPENAI_API_KEY")
    if k: return k
    try:
        return st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        return None

# -----------------------------
# ìœ í‹¸
# -----------------------------
def _clean(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "")).strip()

def similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, a, b).ratio()

def chunk_text(text: str, size: int = 900, overlap: int = 150) -> List[str]:
    """ê°„ë‹¨ ì²­í¬(ì—…ë¡œë“œ ë¬¸ì„œìš©)."""
    t = re.sub(r"\s+", " ", text or "").strip()
    if not t: return []
    out, i = [], 0
    while i < len(t):
        j = min(len(t), i + size)
        out.append(t[i:j])
        if j == len(t): break
        i = max(0, j - overlap)
    return out

# -----------------------------
# ì‚¬ì´ë“œë°”: ì„¤ì •
# -----------------------------
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    api_key = load_api_key()
    if not api_key:
        st.info("í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” secrets.tomlì— OPENAI_API_KEYê°€ ì—†ìœ¼ë©´ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        api_key = st.text_input("OPENAI_API_KEY", type="password")

    MODEL = st.selectbox("ì±— ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small", "text-embedding-3-large"], index=0)

    with st.expander("ë””ë²„ê·¸: ìƒíƒœ/ë²„ì „"):
        st.write({"api_key_loaded": bool(api_key), "model": MODEL, "embed": EMBED_MODEL})

if not api_key or OpenAI is None:
    st.error("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. (requirements.txtì— openai í¬í•¨)")
    st.stop()

client = OpenAI(api_key=api_key)

# -----------------------------
# ìºì‹œ(ì†ë„ ê°œì„ )
# -----------------------------
@st.cache_data(ttl=3600)
def cached_embeddings(model: str, texts: List[str]) -> np.ndarray:
    """ë™ì¼ í…ìŠ¤íŠ¸ ì¬ì„ë² ë”© ë°©ì§€."""
    if not texts: return np.zeros((0, 3), dtype=np.float32)
    r = client.embeddings.create(model=model, input=texts)
    return np.array([d.embedding for d in r.data], dtype=np.float32)

def embed_texts(texts: List[str]) -> np.ndarray:
    return cached_embeddings(EMBED_MODEL, texts)

def cosine_topk(mat: np.ndarray, q: np.ndarray, k: int = 4):
    if mat.size == 0: return np.array([]), np.array([], dtype=int)
    mn = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
    qn = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

# -----------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------------
default_state = {
    "company": {"name": "", "homepage": "", "role": ""},
    "rag_store": {"chunks": [], "embeds": None},
    "current_question": "",
    "answer_text": "",
    "history": [],  # [{ts, question, user_answer, score, feedback, competencies(list[int]|None)}]
}
for k, v in default_state.items():
    if k not in st.session_state:
        st.session_state[k] = v

# -----------------------------
# â‘  íšŒì‚¬/ì§ë¬´ ì…ë ¥
# -----------------------------
st.subheader("â‘  íšŒì‚¬/ì§ë¬´ ì…ë ¥")
c_col, r_col = st.columns([2, 1])
with c_col:
    company_name = st.text_input("íšŒì‚¬ ì´ë¦„", placeholder="ì˜ˆ: ë„¤ì´ë²„ / ì¹´ì¹´ì˜¤ / ì‚¼ì„±SDS",
                                 value=st.session_state["company"]["name"])
with r_col:
    role_title = st.text_input("ì§€ì› ì§ë¬´ëª…", placeholder="ë°ì´í„° ì• ë„ë¦¬ìŠ¤íŠ¸ / ML ì—”ì§€ë‹ˆì–´ ...",
                               value=st.session_state["company"]["role"])

home_url = st.text_input("í™ˆí˜ì´ì§€ URL(ì„ íƒ)", placeholder="https://...",
                         value=st.session_state["company"]["homepage"])

if st.button("íšŒì‚¬/ì§ë¬´ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
    st.session_state["company"] = {
        "name": company_name.strip(),
        "homepage": home_url.strip(),
        "role": role_title.strip()
    }
    # â†“ ê²°ê³¼ ì´ˆê¸°í™”
    st.session_state["rag_store"] = {"chunks": [], "embeds": None}
    st.session_state["current_question"] = ""
    st.session_state["answer_text"] = ""
    st.session_state["history"] = []
    st.success("íšŒì‚¬ ì •ë³´ ê°±ì‹  ë° ê²°ê³¼ ì´ˆê¸°í™” ì™„ë£Œ")

if st.session_state["company"]["name"]:
    st.markdown(f"- **íšŒì‚¬ëª…**: {st.session_state['company']['name']}"
                f" / **ì§ë¬´**: {st.session_state['company']['role'] or 'â€”'}")
    if st.session_state["company"]["homepage"]:
        st.markdown(f"- **í™ˆí˜ì´ì§€**: {st.session_state['company']['homepage']}")

# -----------------------------
# â‘¡ RAG ì˜µì…˜(ì„ íƒ)
# -----------------------------
st.subheader("â‘¡ RAG ì˜µì…˜(ì„ íƒ)")
with st.expander("íšŒì‚¬ ë¬¸ì„œ ì—…ë¡œë“œ / ì¸ë±ì‹±"):
    rag_on = st.toggle("íšŒì‚¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸/ì½”ì¹­ ì‚¬ìš©", value=True, key="rag_on")
    topk = st.slider("ê²€ìƒ‰ ìƒìœ„ K", 1, 8, 4, 1)
    ups = st.file_uploader("íšŒì‚¬ ë¬¸ì„œ ì—…ë¡œë“œ (TXT/MD/PDF)", type=["txt", "md", "pdf"], accept_multiple_files=True)
    size = st.slider("ì²­í¬ ê¸¸ì´", 400, 2000, 900, 100)
    ovlp = st.slider("ì˜¤ë²„ë©", 0, 400, 150, 10)

    if ups:
        chunks = []
        for u in ups:
            raw = u.read()
            name = u.name.lower()
            text = ""
            if name.endswith((".txt", ".md")):
                for enc in ("utf-8", "cp949", "euc-kr"):
                    try:
                        text = raw.decode(enc)
                        break
                    except Exception:
                        text = ""
                if not text:
                    text = raw.decode("utf-8", errors="ignore")
            elif name.endswith(".pdf"):
                try:
                    import pypdf
                    reader = pypdf.PdfReader(io.BytesIO(raw))
                    text = "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
                except Exception:
                    text = ""
            if text:
                chunks += chunk_text(text, size=size, overlap=ovlp)
        if chunks:
            embs = embed_texts(chunks)
            st.session_state["rag_store"] = {"chunks": chunks, "embeds": embs}
            st.success(f"ì¸ë±ì‹± ì™„ë£Œ: ì²­í¬ {len(chunks)}ê°œ")

# -----------------------------
# â‘¢ ì§ˆë¬¸ ìƒì„±
# -----------------------------
st.subheader("â‘¢ ì§ˆë¬¸ ìƒì„±")
TYPE_INSTR = {
    "í–‰ë™(STAR)": "ê³¼ê±° ì‹¤ë¬´ ì‚¬ë¡€ë¥¼ ì´ëŒì–´ë‚´ëŠ” STAR í–‰ë™ ì§ˆë¬¸",
    "ê¸°ìˆ  ì‹¬ì¸µ": "ì„±ëŠ¥/ë¹„ìš©/ì§€ì—°/ì •í™•ë„/ìš´ì˜ê¹Œì§€ íŒŒê³ ë“œëŠ” ê¸°ìˆ  ì‹¬ì¸µ ì§ˆë¬¸",
    "í•µì‹¬ê°€ì¹˜ ì í•©ì„±": "ê°€ì¹˜ê´€/íƒœë„/í˜‘ì—… ìŠ¤íƒ€ì¼ì„ ê²€ì¦í•˜ëŠ” ì§ˆë¬¸",
    "ì—­ì§ˆë¬¸": "ì§€ì›ìê°€ íšŒì‚¬ë¥¼ í‰ê°€í•˜ëŠ” ì—­ì§ˆë¬¸",
}
q_type = st.selectbox("ì§ˆë¬¸ ìœ í˜•", list(TYPE_INSTR.keys()))
level = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´", "ë¯¸ë“¤", "ì‹œë‹ˆì–´"])
hint = st.text_input("ì§ˆë¬¸ ìƒì„± íŒíŠ¸(ì„ íƒ)", placeholder="ì˜ˆ: ì „í™˜ í¼ë„ / ëª¨ë¸ ì„±ëŠ¥-ë¹„ìš© / ë°ì´í„° í’ˆì§ˆ")

def retrieve_supports(qtext: str, k: int) -> List[Tuple[str, float, str]]:
    store = st.session_state["rag_store"]
    chs, embs = store.get("chunks", []), store.get("embeds")
    if not st.session_state.get("rag_on") or embs is None or not chs:
        return []
    qv = embed_texts([qtext])
    s, idx = cosine_topk(embs, qv, k=k)
    return [("íšŒì‚¬ìë£Œ", float(sc), chs[int(i)]) for sc, i in zip(s, idx)]

def choose_diverse(cands: List[str], history: List[str]) -> str:
    """ì´ì „ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•˜ì§€ ì•Šê²Œ í•œ ê°œ ì„ íƒ."""
    if not cands: return ""
    if not history: return random.choice(cands)
    best, best_s = None, 1e9
    for q in cands:
        sims = [similarity(q, h) for h in history] or [0.0]
        s = (sum(sims)/len(sims)) + 0.35*np.std(sims)
        if s < best_s:
            best_s, best = s, q
    return best

if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary", use_container_width=True):
    st.session_state["answer_text"] = ""  # ì´ì „ ë‹µë³€ ë¹„ìš°ê¸°(ìš”ì²­ ë°˜ì˜)
    try:
        company = st.session_state["company"]
        ctx_lines = [
            f"[íšŒì‚¬ëª…] {company.get('name','')}",
            f"[ì§ë¬´] {company.get('role','')}",
        ]
        ctx = "\n".join(ctx_lines)

        focuses = []
        if hint.strip(): focuses.append(hint.strip())
        if company.get("role"): focuses.append(company["role"])

        # ì„ íƒì  RAG ê¸°ë°˜ í‚¤ì›Œë“œ ë³´ê°•
        supports = []
        if st.session_state.get("rag_on"):
            supports = retrieve_supports(hint or company.get("role", ""), k=topk)
            for _, _, txt in supports[:3]:
                for frag in re.split(r"[â€¢\-\n\.]", txt):
                    frag = frag.strip()
                    if 6 < len(frag) < 80:
                        focuses.append(frag)
        focuses = list(dict.fromkeys(focuses))[:6]

        sys = f"""ë„ˆëŠ” '{q_type}' ìœ í˜•({TYPE_INSTR[q_type]})ì˜ ì§ˆë¬¸ 6ê°œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤.
ê° ì§ˆë¬¸ì€ ê´€ì /í˜•íƒœ/í‚¤ì›Œë“œë¥¼ ë‹¤ë¥´ê²Œ í•˜ê³ , ë‚œì´ë„ëŠ” {level}ì— ë§ì¶˜ë‹¤.
í¬ë§·: 1) ... 2) ... 3) ... (í•œ ì¤„ì”©)"""
        user = f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n[í¬ì»¤ìŠ¤]\n- " + "\n- ".join(focuses) if focuses else f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}"

        r = client.chat.completions.create(model=MODEL, temperature=0.95,
                                           messages=[{"role":"system","content":sys},
                                                     {"role":"user","content":user}])
        raw = r.choices[0].message.content.strip()
        cands = [re.sub(r'^\s*\d+\)\s*', '', ln).strip()
                 for ln in raw.splitlines() if re.match(r'^\s*\d+\)', ln)]
        if not cands:
            cands = [ln.strip("- ").strip() for ln in raw.splitlines() if ln.strip()][:6]

        hist_q = [h["question"] for h in st.session_state["history"]][-10:]
        st.session_state["current_question"] = choose_diverse(cands, hist_q) or cands[0]
        st.session_state["last_supports_q"] = supports
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")

st.text_area("ì§ˆë¬¸", height=110, value=st.session_state.get("current_question", ""))

# -----------------------------
# â‘£ ë‹µë³€/ì½”ì¹­ & ì ìˆ˜ ì¼ì›í™”
# -----------------------------
st.subheader("â‘£ ë‚˜ì˜ ë‹µë³€ / ì½”ì¹­")
AXES = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def coach_answer(company: dict, question: str, answer: str,
                 supports: List[Tuple[str, float, str]]) -> dict:
    # í† í° ë‹¤ì´ì–´íŠ¸: ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì‚¬ìš©
    q_trim = (question or "")[:500]
    a_trim = (answer or "")[:1200]

    rag = ""
    if supports:
        rag = "\n[íšŒì‚¬ ê·¼ê±°(ë°œì·Œ)]\n" + "\n".join([f"- ({s:.3f}) {txt[:300]}" for _, s, txt in supports])

    sys = f"""ë„ˆëŠ” í•œêµ­ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ë§Œ ì¶œë ¥:
1) ì´ì : NN/100
2) ê°•ì : â€¢ 2~3ê°œ
3) ë¦¬ìŠ¤í¬: â€¢ 2~3ê°œ
4) ê°œì„  í¬ì¸íŠ¸: â€¢ 3ê°œ (í–‰ë™Â·ì§€í‘œÂ·ì„íŒ©íŠ¸ ì¤‘ì‹¬)
5) ìˆ˜ì •ë³¸ ë‹µë³€: STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ ê°„ê²°íˆ
6) ì—­ëŸ‰ ì ìˆ˜(ê° 0~20, ë¹„ì ìš©ì€ '-' ê·¸ëŒ€ë¡œ): [{', '.join(AXES)}] â€” 5ê°œ ê°’ì„ ì‰¼í‘œë¡œ ì¶œë ¥
"""
    user = f"""[íšŒì‚¬/ì§ë¬´] {company.get('name','')} / {company.get('role','')}
{rag}
[ë©´ì ‘ ì§ˆë¬¸]
{q_trim}

[í›„ë³´ì ë‹µë³€]
{a_trim}
"""

    resp = client.chat.completions.create(model=MODEL, temperature=0.35,
                                          messages=[{"role":"system","content":sys},
                                                    {"role":"user","content":user}])
    content = resp.choices[0].message.content.strip()

    # (A) ëª¨ë¸ì´ ë³¸ë¬¸ì— ì“´ ì´ì (ìˆìœ¼ë©´ íŒŒì‹±)
    score = None
    m = re.search(r'ì´ì \s*[:ï¼š]\s*(\d{1,3})', content)
    if m:
        score = max(0, min(100, int(m.group(1))))

    # (B) ì—­ëŸ‰ 5ê°œ(0~20) íŒŒì‹±
    last_line = content.splitlines()[-1] if content.splitlines() else ""
    nums = re.findall(r'\b(\d{1,2})\b', last_line)
    if len(nums) < 5:
        nums = re.findall(r'\b(\d{1,2})\b', content)
    competencies = None
    if len(nums) >= 5:
        cand = [int(x) for x in nums[:5]]
        # 0~5 ë˜ëŠ” 0~10ë¡œ ë‚˜ì˜¬ ë•Œ ë³´ì •
        if all(0 <= x <= 5 for x in cand):
            cand = [x*4 for x in cand]
        elif all(0 <= x <= 10 for x in cand) and any(x > 5 for x in cand):
            cand = [x*2 for x in cand]
        competencies = [max(0, min(20, x)) for x in cand]

    # âœ… ìµœì¢… ì´ì : ì—­ëŸ‰ í‰ê· Ã—5ê°€ ìš°ì„ , ì—†ìœ¼ë©´ ëª¨ë¸ ì´ì , ë‘˜ ë‹¤ ì—†ìœ¼ë©´ 0
    if competencies and len(competencies) == 5:
        final_score = int(round(sum(competencies) / 5.0 * 5))
    else:
        final_score = score if score is not None else 0

    # âœ… ìš°ì¸¡ ë³¸ë¬¸ ì²« ì¤„ì˜ 'ì´ì :' ê°•ì œ ì¹˜í™˜ â†’ ì¢Œ/ìš° í•­ìƒ ë™ì¼
    lines = content.splitlines()
    replaced = False
    for i, L in enumerate(lines[:4]):  # ìƒë‹¨ 3~4ì¤„ë§Œ ë³€ê²½
        if "ì´ì " in L:
            lines[i] = re.sub(r"ì´ì \s*[:ï¼š]\s*\d{1,3}(?:\s*/\s*100)?",
                              f"ì´ì : {final_score}/100", L)
            replaced = True
            break
    if not replaced:
        lines.insert(0, f"ì´ì : {final_score}/100")
    content_fixed = "\n".join(lines)

    return {
        "raw": content_fixed,         # ìš°ì¸¡ì— ë³´ì—¬ì¤„ í”¼ë“œë°±(ì´ì  êµì²´ ì™„ë£Œ)
        "score": final_score,         # ì¢Œì¸¡ metricì— ë³´ì—¬ì¤„ ì´ì 
        "competencies": competencies  # [0..20]*5 ë˜ëŠ” None
    }

ans = st.text_area("ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš” (STAR ê¶Œì¥: ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)",
                   height=180, key="answer_text")

if st.button("ì±„ì  & ì½”ì¹­", type="primary", use_container_width=True):
    if not st.session_state.get("current_question"):
        st.warning("ë¨¼ì € 'ìƒˆ ì§ˆë¬¸ ë°›ê¸°'ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state["answer_text"].strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì½”ì¹­ ì¤‘..."):
            # RAG ê·¼ê±°(ì§ˆë¬¸+ë‹µë³€ ì¼ë¶€ ê¸°ë°˜)
            sups = []
            if st.session_state.get("rag_on"):
                q_for_rag = (st.session_state["current_question"][:500]
                             + "\n" + st.session_state["answer_text"][:800])
                sups = retrieve_supports(q_for_rag, k=topk)

            res = coach_answer(st.session_state["company"],
                               st.session_state["current_question"],
                               st.session_state["answer_text"],
                               sups)

            st.session_state["history"].append({
                "ts": pd.Timestamp.now(),
                "question": st.session_state["current_question"],
                "user_answer": st.session_state["answer_text"],
                "score": res["score"],
                "feedback": res["raw"],
                "competencies": res["competencies"],  # [0..20]*5 or None
            })

# -----------------------------
# â‘¤ í”¼ë“œë°± ê²°ê³¼(ì¢Œ/ìš° ì´ì  ë™ì¼)
# -----------------------------
st.divider()
st.subheader("í”¼ë“œë°± ê²°ê³¼")

if st.session_state["history"]:
    last = st.session_state["history"][-1]
    total = last["score"]
    c1, c2 = st.columns([1, 3])
    with c1:
        st.metric("ì´ì (/100)", total)
    with c2:
        # ìš°ì¸¡ ë³¸ë¬¸ ì²« ì¤„ì˜ ì´ì ë„ ìœ„ì™€ ë™ì¼í•˜ê²Œ ì¹˜í™˜ë˜ì–´ ìˆìŒ
        st.markdown(last["feedback"])
else:
    st.info("ì•„ì§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# â‘¥ ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì ) + í•©ê³„ ì»¬ëŸ¼
# -----------------------------
st.divider()
st.subheader("ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")

COMP_AXES = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def comp_df(history):
    rows = []
    for h in history:
        cs = h.get("competencies")
        if not cs or len(cs) != 5:
            continue
        fixed = []
        for v in cs:
            try:
                x = int(v)
            except Exception:
                x = 0
            fixed.append(max(0, min(20, x)))  # 0~20 ë³´ì •
        rows.append(fixed)
    if not rows:
        return None
    df = pd.DataFrame(rows, columns=COMP_AXES)
    df["í•©ê³„"] = df[COMP_AXES].sum(axis=1)  # 5ì¶• í•©: 0~100
    return df

cdf = comp_df(st.session_state["history"])
if cdf is not None:
    avg = cdf[COMP_AXES].mean().tolist()  # 0~20
    avg = [float(x) for x in avg]
    if PLOTLY_OK:
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=avg + [avg[0]], theta=COMP_AXES + [COMP_AXES[0]], fill='toself'))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 20])),
                          showlegend=False, height=420)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.bar_chart(pd.DataFrame({"score": avg}, index=COMP_AXES))

    # âœ… í•©ê³„ í¬í•¨ í…Œì´ë¸”
    st.dataframe(cdf, use_container_width=True)
else:
    st.caption("ì•„ì§ ì—­ëŸ‰ ì ìˆ˜ê°€ íŒŒì‹±ëœ ì½”ì¹­ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# â‘¦ ì„¸ì…˜ ë¦¬í¬íŠ¸(CSV)
# -----------------------------
st.divider()
st.subheader("ì„¸ì…˜ ë¦¬í¬íŠ¸ (CSV)")

def build_report(history):
    rows = []
    for h in history:
        row = {
            "timestamp": h["ts"],
            "question": h["question"],
            "user_answer": h["user_answer"],
            "score": h["score"],
            "feedback_raw": h["feedback"]
        }
        cs = h.get("competencies") or []
        for k, v in zip(COMP_AXES, cs[:5]):
            row[f"comp_{k}"] = v
        row["comp_sum"] = sum([int(v) for v in cs[:5] if isinstance(v, (int, float))])
        rows.append(row)
    if not rows:
        return pd.DataFrame(columns=["timestamp","question","user_answer","score","feedback_raw"])
    return pd.DataFrame(rows)

rep = build_report(st.session_state["history"])
st.download_button("CSV ë‹¤ìš´ë¡œë“œ",
                   data=rep.to_csv(index=False).encode("utf-8-sig"),
                   file_name="interview_session_report.csv",
                   mime="text/csv")

st.caption("ì´ì  ì¼ì›í™”(ì—­ëŸ‰ í‰ê· Ã—5) ì ìš©, ë ˆì´ë” í•©ê³„ ì»¬ëŸ¼ ì¶”ê°€, ìºì‹œ/í† í° ë‹¤ì´ì–´íŠ¸ë¡œ ì†ë„ ê°œì„ ")
