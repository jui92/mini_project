# -*- coding: utf-8 -*-
# ============================================
# íšŒì‚¬ íŠ¹í™” ê°€ìƒ ë©´ì ‘ ì½”ì¹˜ (í…ìŠ¤íŠ¸ ì „ìš©, RAG+ë ˆãƒ¼ãƒ€+CSV)
# ============================================
# ì˜ì¡´: streamlit, openai(>=1.x), faiss-cpu, pypdf, plotly, pandas, numpy
# ì‹¤í–‰:
#   pip install streamlit openai faiss-cpu pypdf plotly pandas numpy
#   streamlit run interview_coach_rag.py
# API í‚¤: .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY
# ============================================

import os, json, io, re, textwrap, time, tempfile
from typing import List, Dict, Tuple
import numpy as np
import pandas as pd
import streamlit as st

# OpenAI SDK
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `pip install openai` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.stop()

# ë²¡í„° ê²€ìƒ‰: FAISS
try:
    import faiss
except ImportError:
    faiss = None

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
try:
    import pypdf
except ImportError:
    pypdf = None

# Radar chart (Plotly)
import plotly.graph_objects as go

# =========================
# Streamlit ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="íšŒì‚¬ íŠ¹í™” ê°€ìƒ ë©´ì ‘ ì½”ì¹˜ (RAG+Radar+CSV)", page_icon="ğŸ¯", layout="wide")

# ===== ì‚¬ì´ë“œë°”: ì„¤ì • =====
with st.sidebar:
    st.title("ğŸ¯ ê°€ìƒ ë©´ì ‘ ì½”ì¹˜ (í…ìŠ¤íŠ¸ ì „ìš©)")
    st.caption("íšŒì‚¬ ë§ì¶¤ ì§ˆë¬¸ + ë¬¸ì„œ ê·¼ê±° RAG + ì—­ëŸ‰ ë ˆì´ë” + CSV ë¦¬í¬íŠ¸")

    # API Key
    API_KEY = (
        st.secrets.get("OPENAI_API_KEY", None)
        if hasattr(st, "secrets") else None
    ) or os.getenv("OPENAI_API_KEY")

    if not API_KEY:
        API_KEY = st.text_input("OpenAI API Key", type="password")

    MODEL = st.selectbox("ëª¨ë¸", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small", "text-embedding-3-large"], index=0)

    st.divider()
    st.markdown("#### íšŒì‚¬/ì§ë¬´ ì„¤ì •")

    # íšŒì‚¬ ìš”ì•½ JSON ë¶ˆëŸ¬ì˜¤ê¸°/ì—…ë¡œë“œ
    data_dir = "data/companies"
    os.makedirs(data_dir, exist_ok=True)

    # ê¸°ë³¸ ì˜ˆì‹œ íŒŒì¼ ìë™ ìƒì„±
    defaults = {
        "acme.json": {
            "company_name": "ACME",
            "values": ["ê³ ê°ì§‘ì°©", "ë°ì´í„°ê¸°ë°˜", "ì£¼ë„ì  ì‹¤í–‰"],
            "role": "ë°ì´í„° ì• ë„ë¦¬ìŠ¤íŠ¸",
            "role_requirements": [
                "SQL/EDA ìˆ™ë ¨", "ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ì§€í‘œ ì„¤ê³„", "ëŒ€ì‹œë³´ë“œ/ë¦¬í¬íŠ¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"
            ],
            "recent_projects": ["êµ¬ë… ì „í™˜ í¼ë„ ìµœì í™”", "ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ íŒŒì¼ëŸ¿"],
            "language": "ko"
        },
        "contoso.json": {
            "company_name": "Contoso",
            "values": ["ì†Œìœ ê°", "í˜‘ì—…", "ê³ ê° ì„±ê³µ"],
            "role": "ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´",
            "role_requirements": [
                "ëª¨ë¸ë§/ì„œë¹™ íŒŒì´í”„ë¼ì¸", "ê´€ì¸¡ì„±/ëª¨ë‹ˆí„°ë§", "ì„±ëŠ¥-ë¹„ìš© ìµœì í™”"
            ],
            "recent_projects": ["ì¶”ì²œ ì‹œìŠ¤í…œ ë¦¬ë­í‚¹", "A/B í…ŒìŠ¤íŠ¸ í”Œë«í¼ ê°œì„ "],
            "language": "ko"
        }
    }
    for fn, payload in defaults.items():
        path = os.path.join(data_dir, fn)
        if not os.path.exists(path):
            with open(path, "w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False, indent=2)

    files = [f for f in os.listdir(data_dir) if f.endswith(".json")]
    company_file = st.selectbox("íšŒì‚¬ í”„ë¡œí•„ íŒŒì¼", files, index=0)

    uploaded_company = st.file_uploader("ë˜ëŠ” íšŒì‚¬ í”„ë¡œí•„ JSON ì—…ë¡œë“œ", type=["json"])
    if uploaded_company is not None:
        try:
            company = json.load(uploaded_company)
        except Exception as e:
            st.error(f"íšŒì‚¬ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            st.stop()
    else:
        company = json.load(open(os.path.join(data_dir, company_file), "r", encoding="utf-8"))

    st.markdown("#### ì§ˆë¬¸ ì˜µì…˜")
    q_type = st.selectbox("ì§ˆë¬¸ ìœ í˜•", ["í–‰ë™(STAR)", "ê¸°ìˆ  ì‹¬ì¸µ", "í•µì‹¬ê°€ì¹˜ ì í•©ì„±", "ì—­ì§ˆë¬¸"], index=0)
    level = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´", "ë¯¸ë“¤", "ì‹œë‹ˆì–´"], index=0)

    st.markdown("#### RAG (ì„ íƒ)")
    rag_enabled = st.toggle("íšŒì‚¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸/ì½”ì¹­ ì‚¬ìš© (RAG)", value=True)
    chunk_size = st.slider("ì²­í¬ ê¸¸ì´(ë¬¸ì)", min_value=400, max_value=2000, value=900, step=100)
    chunk_overlap = st.slider("ì˜¤ë²„ë©(ë¬¸ì)", min_value=0, max_value=400, value=150, step=10)
    top_k = st.slider("ê²€ìƒ‰ ìƒìœ„ K", min_value=1, max_value=8, value=4, step=1)

    st.caption("â€» TXT/MD/PDF ì—…ë¡œë“œ ê°€ëŠ¥(PDFëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ). íŒŒì¼ì€ ì„¸ì…˜ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
    docs = st.file_uploader("íšŒì‚¬ ë¬¸ì„œ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥)", type=["txt", "md", "pdf"], accept_multiple_files=True)

# =========================
# ê³µìš© í•¨ìˆ˜
# =========================
def build_company_context(c: dict) -> str:
    return textwrap.dedent(f"""
    [íšŒì‚¬ëª…] {c.get('company_name','')}
    [í•µì‹¬ê°€ì¹˜] {", ".join(c.get('values', []))}
    [ì§ë¬´] {c.get('role','')}
    [ì£¼ìš” ìš”êµ¬ì—­ëŸ‰] {", ".join(c.get('role_requirements', []))}
    [ìµœê·¼ í”„ë¡œì íŠ¸] {", ".join(c.get('recent_projects', []))}
    """)

def read_file_to_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt", ".md")):
        try:
            return data.decode("utf-8")
        except UnicodeDecodeError:
            return data.decode("cp949", errors="ignore")
    elif name.endswith(".pdf"):
        if pypdf is None:
            st.warning("pypdfê°€ ì„¤ì¹˜ë˜ì–´ì•¼ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. `pip install pypdf`")
            return ""
        try:
            reader = pypdf.PdfReader(io.BytesIO(data))
            pages = []
            for i in range(len(reader.pages)):
                try:
                    pages.append(reader.pages[i].extract_text() or "")
                except Exception:
                    pages.append("")
            return "\n\n".join(pages)
        except Exception as e:
            st.warning(f"PDF íŒŒì‹± ì‹¤íŒ¨({uploaded.name}): {e}")
            return ""
    else:
        return ""

def chunk_text(text: str, size: int = 900, overlap: int = 150) -> List[str]:
    text = re.sub(r"\s+", " ", text).strip()
    if not text:
        return []
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + size)
        chunks.append(text[start:end])
        start = end - overlap
        if start < 0:
            start = 0
        if start >= len(text):
            break
    return chunks

def embed_texts(client: OpenAI, embed_model: str, texts: List[str]) -> np.ndarray:
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    # OpenAI SDK 1.x: embeddings.create
    resp = client.embeddings.create(model=embed_model, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def build_faiss_index(embeds: np.ndarray):
    if faiss is None:
        return None
    d = embeds.shape[1]
    index = faiss.IndexFlatIP(d)  # Inner Product (cosine ìœ„í•´ ì •ê·œí™” ì „ì œ)
    # ì •ê·œí™”
    norms = np.linalg.norm(embeds, axis=1, keepdims=True) + 1e-12
    normed = embeds / norms
    index.add(normed)
    return index, normed

def faiss_search(index, normed_embeds: np.ndarray, query_vec: np.ndarray, k: int = 4):
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    D, I = index.search(qn, k)
    return D[0], I[0]

def cosine_topk(matrix: np.ndarray, query: np.ndarray, k: int = 4):
    # fallback (faiss ì—†ëŠ” ê²½ìš°)
    qn = query / (np.linalg.norm(query, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    scores = sims[idx]
    return scores, idx

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸
# =========================
if not API_KEY:
    st.warning("API Keyë¥¼ ì…ë ¥í•˜ë©´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()
client = OpenAI(api_key=API_KEY)

# =========================
# RAG ì¤€ë¹„: ë¬¸ì„œâ†’ì²­í¬â†’ì„ë² ë”©â†’ì¸ë±ìŠ¤
# =========================
if "rag_store" not in st.session_state:
    st.session_state.rag_store = {
        "chunks": [],          # List[str]
        "embeds": None,        # np.ndarray
        "index": None          # FAISS index (or None)
    }

if rag_enabled and docs:
    with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
        all_chunks, src_map = [], []  # src_map: (filename, chunk_id)
        for up in docs:
            text = read_file_to_text(up)
            if not text:
                continue
            chs = chunk_text(text, chunk_size, chunk_overlap)
            all_chunks.extend(chs)
            src_map.extend([(up.name, i) for i in range(len(chs))])

        if all_chunks:
            embeds = embed_texts(client, EMBED_MODEL, all_chunks)
            st.session_state.rag_store["chunks"] = all_chunks
            st.session_state.rag_store["embeds"] = embeds
            if faiss is not None and embeds.shape[0] > 0:
                index, normed = build_faiss_index(embeds)
                st.session_state.rag_store["index"] = (index, normed)
            else:
                st.session_state.rag_store["index"] = None
            st.success(f"RAG ì¤€ë¹„ ì™„ë£Œ: ì²­í¬ {len(all_chunks)}ê°œ")
        else:
            st.info("ì—…ë¡œë“œ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# í”„ë¡¬í”„íŠ¸ ë¹Œë”
# =========================
def gen_question(company: dict, qtype: str, level: str, supports: List[Tuple[str, float, str]]) -> str:
    # supports: [(source_name, score, text_chunk)]
    ctx = build_company_context(company)
    rag_note = ""
    if supports:
        joined = "\n\n".join([f"- ({s:.3f}) {src} :: {txt[:400]}" for (src, s, txt) in supports])
        rag_note = f"\n[íšŒì‚¬ ê·¼ê±° ë¬¸ì„œ ë°œì·Œ]\n{joined}\n"

    sys = f"""ë„ˆëŠ” '{company.get('company_name','')}'ì˜ '{company.get('role','')}' ë©´ì ‘ê´€ì´ë‹¤.
íšŒì‚¬ ë§¥ë½ê³¼ (ìˆë‹¤ë©´) ì•„ë˜ ê·¼ê±° ë¬¸ì„œë¥¼ ë°˜ì˜í•˜ì—¬ {qtype} ìœ í˜•ì˜ **êµ¬ì²´ì  ì§ˆë¬¸ 1ê°œë§Œ** í•œêµ­ì–´ë¡œ ìƒì„±í•˜ë¼.
ì§€ì›ìê°€ í–‰ë™/ì§€í‘œ/ì„íŒ©íŠ¸ë¥¼ ë“œëŸ¬ë‚´ë„ë¡ í•˜ë©°, ë‚œì´ë„/ì—°ì°¨ëŠ” {level}ì— ë§ì¶˜ë‹¤.
ì„œë¡ /ë¶€ì—° ê¸ˆì§€. ê²°ê³¼ëŠ” ì§ˆë¬¸ ë¬¸ì¥ í•œ ì¤„ë§Œ."""
    user = f"""[íšŒì‚¬ ì»¨í…ìŠ¤íŠ¸]
{ctx}
{rag_note}"""

    resp = client.chat.completions.create(
        model=MODEL, temperature=0.7,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    return resp.choices[0].message.content.strip()

def coach_answer(company: dict, question: str, user_answer: str, supports: List[Tuple[str, float, str]]) -> Dict:
    ctx = build_company_context(company)
    rag_note = ""
    if supports:
        joined = "\n\n".join([f"- ({s:.3f}) {src} :: {txt[:600]}" for (src, s, txt) in supports])
        rag_note = f"\n[íšŒì‚¬ ê·¼ê±° ë¬¸ì„œ ë°œì·Œ]\n{joined}\n"

    # ì—­ëŸ‰ ë ˆì´ë”ìš© ì¹´í…Œê³ ë¦¬: 0~5ì ì”© ìš”ì²­ (ì •ìˆ˜)
    competencies = [
        "ë¬¸ì œì •ì˜", "ë°ì´í„°/ì§€í‘œ", "ì‹¤í–‰ë ¥/ì£¼ë„ì„±", "í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "ê³ ê°ê°€ì¹˜"
    ]
    comp_str = ", ".join(competencies)

    sys = f"""ë„ˆëŠ” í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. í•œêµ­ì–´ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ë‹µí•˜ë¼:
1) ì´ì : 0~10 ì •ìˆ˜ 1ê°œ
2) ê°•ì : 2~3ê°œ ë¶ˆë¦¿
3) ë¦¬ìŠ¤í¬: 2~3ê°œ ë¶ˆë¦¿
4) ê°œì„  í¬ì¸íŠ¸: 3ê°œ ë¶ˆë¦¿ (í–‰ë™Â·ì§€í‘œÂ·ì„íŒ©íŠ¸ ì¤‘ì‹¬)
5) ìˆ˜ì •ë³¸ ë‹µë³€: STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼) êµ¬ì¡°ë¡œ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ
6) ì—­ëŸ‰ ì ìˆ˜: [{comp_str}] ê°ê° 0~5 ì •ìˆ˜ (í•œ ì¤„ì— ì‰¼í‘œë¡œ êµ¬ë¶„)
ì¶”ê°€ ì„¤ëª…ì€ ê¸ˆì§€. í˜•ì‹ì„ ìœ ì§€í•˜ë¼."""
    user = f"""[íšŒì‚¬ ì»¨í…ìŠ¤íŠ¸]
{ctx}
{rag_note}
[ë©´ì ‘ ì§ˆë¬¸]
{question}

[í›„ë³´ì ë‹µë³€]
{user_answer}
"""

    resp = client.chat.completions.create(
        model=MODEL, temperature=0.4,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    content = resp.choices[0].message.content.strip()

    # ì´ì  íŒŒì‹± (ì²« ë²ˆì§¸ 0-10 ì •ìˆ˜)
    m = re.search(r'([0-9]{1,2})\s*(?:/10|ì |$)', content)
    score = None
    if m:
        try:
            score = int(m.group(1))
            score = max(0, min(10, score))
        except:
            pass

    # ì—­ëŸ‰ ì ìˆ˜ íŒŒì‹±: "ì—­ëŸ‰ ì ìˆ˜:" ë¼ì¸ì´ ìˆë‹¤ë©´ ìˆ«ì 5ê°œ ì¶”ì¶œ
    comp_scores = None
    comp_line = None
    for line in content.splitlines():
        if "ì—­ëŸ‰" in line and any(k in line for k in ["ì ìˆ˜", "ì "]):
            comp_line = line
            break
    if comp_line is None:
        # ë§ˆì§€ë§‰ ì¤„ ê°€ì •
        comp_line = content.splitlines()[-1]
    nums = re.findall(r'\b([0-5])\b', comp_line)
    if len(nums) >= 5:
        comp_scores = [int(x) for x in nums[:5]]

    return {"raw": content, "score": score, "competencies": comp_scores}

# =========================
# ì„¸ì…˜ ìƒíƒœ
# =========================
if "history" not in st.session_state:
    st.session_state.history = []  # [{q, a, score, feedback, supports, comp_scores, ts}]

if "current_question" not in st.session_state:
    st.session_state.current_question = ""

# =========================
# ê²€ìƒ‰ ìœ í‹¸
# =========================
def retrieve_supports(query_text: str, k: int) -> List[Tuple[str, float, str]]:
    """ì§ˆë¬¸ ìƒì„±/ì½”ì¹­ ì „ì— RAG ì»¨í…ìŠ¤íŠ¸ë¡œ ì“¸ ê·¼ê±° ì²­í¬ë¥¼ ë°˜í™˜
       ë¦¬í„´: [(source, score, chunk_text), ...]"""
    store = st.session_state.rag_store
    chunks = store.get("chunks", [])
    embeds = store.get("embeds", None)
    if not rag_enabled or embeds is None or len(chunks) == 0:
        return []
    qv = embed_texts(client, EMBED_MODEL, [query_text])
    if store["index"] and faiss is not None:
        index, normed = store["index"]
        scores, idxs = faiss_search(index, normed, qv, k=k)
    else:
        scores, idxs = cosine_topk(embeds, qv, k=k)
    out = []
    for s, i in zip(scores, idxs):
        out.append(("ì—…ë¡œë“œë¬¸ì„œ", float(s), chunks[int(i)]))
    return out

# =========================
# UI ë³¸ë¬¸
# =========================
left, right = st.columns([1, 1])

with left:
    st.header("â‘  ì§ˆë¬¸ ìƒì„±")
    st.markdown("**ì„ íƒí•œ íšŒì‚¬ ìš”ì•½**")
    st.json(company, expanded=False)

    prompt_hint = st.text_input("ì§ˆë¬¸ ìƒì„± íŒíŠ¸(ì„ íƒ)", placeholder="ì˜ˆ: êµ¬ë… ì „í™˜ í¼ë„ ê´€ë ¨ ê²½í—˜ ìœ„ì£¼ë¡œ ë¬¼ì–´ë´ì¤˜")
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", use_container_width=True):
        try:
            supports = []
            if rag_enabled and (docs or st.session_state.rag_store.get("chunks")):
                # íŒíŠ¸ê°€ ìˆìœ¼ë©´ íŒíŠ¸ë¡œ ê²€ìƒ‰, ì—†ìœ¼ë©´ íšŒì‚¬ roleê³¼ valuesë¡œ ê²€ìƒ‰
                base_q = prompt_hint.strip() or f"{company.get('role','')} {', '.join(company.get('values', []))}"
                supports = retrieve_supports(base_q, top_k)
            q = gen_question(company, q_type, level, supports)
            st.session_state.current_question = q
            st.session_state.last_supports_q = supports
        except Exception as e:
            st.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")

    st.text_area("ì§ˆë¬¸", height=110, value=st.session_state.get("current_question",""))

    # ê·¼ê±° í‘œì‹œ (ì§ˆë¬¸ ìƒì„±ì— ì‚¬ìš©)
    if rag_enabled and st.session_state.get("last_supports_q"):
        with st.expander("ì§ˆë¬¸ ìƒì„±ì— ì‚¬ìš©ëœ ê·¼ê±° ë³´ê¸°"):
            for i, (src, sc, txt) in enumerate(st.session_state.last_supports_q, 1):
                st.markdown(f"**[{i}] {src} (sim={sc:.3f})**\n\n{txt[:600]}{'...' if len(txt)>600 else ''}")
                st.markdown("---")

with right:
    st.header("â‘¡ ë‚˜ì˜ ë‹µë³€")
    answer = st.text_area("ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš” (ê°€ëŠ¥í•˜ë©´ STAR: ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)", height=160)

    # ì½”ì¹­ ì‹¤í–‰
    if st.button("ì±„ì  & ì½”ì¹­", type="primary", use_container_width=True):
        if not st.session_state.get("current_question"):
            st.warning("ë¨¼ì € 'ìƒˆ ì§ˆë¬¸ ë°›ê¸°'ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        elif not answer.strip():
            st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì½”ì¹­ ì¤‘..."):
                try:
                    # ì½”ì¹­ìš© RAG: ì§ˆë¬¸+ë‹µë³€ì„ í•©ì³ ì§ˆì˜ë¡œ ì‚¬ìš©
                    supports = []
                    if rag_enabled and (docs or st.session_state.rag_store.get("chunks")):
                        q_for_rag = st.session_state["current_question"] + "\n" + answer[:800]
                        supports = retrieve_supports(q_for_rag, top_k)

                    res = coach_answer(company, st.session_state["current_question"], answer, supports)
                    st.session_state.history.append({
                        "ts": pd.Timestamp.now(),
                        "question": st.session_state["current_question"],
                        "user_answer": answer,
                        "score": res.get("score"),
                        "feedback": res.get("raw"),
                        "supports": supports,
                        "competencies": res.get("competencies")
                    })
                except Exception as e:
                    st.error(f"ì½”ì¹­ ì˜¤ë¥˜: {e}")

st.divider()
st.subheader("â‘¢ í”¼ë“œë°± ê²°ê³¼")
if st.session_state.history:
    last = st.session_state.history[-1]
    c1, c2 = st.columns([1, 3])
    with c1:
        st.metric("ì´ì (/10)", last.get("score", "â€”"))
    with c2:
        st.markdown(last.get("feedback", ""))

    # ì½”ì¹­ì— ì‚¬ìš©ëœ ê·¼ê±°
    if rag_enabled and last.get("supports"):
        with st.expander("ì½”ì¹­ì— ì‚¬ìš©ëœ ê·¼ê±° ë³´ê¸°"):
            for i, (src, sc, txt) in enumerate(last["supports"], 1):
                st.markdown(f"**[{i}] {src} (sim={sc:.3f})**\n\n{txt[:800]}{'...' if len(txt)>800 else ''}")
                st.markdown("---")

# =========================
# ì—­ëŸ‰ ë ˆì´ë” ì°¨íŠ¸ (ëˆ„ì )
# =========================
st.divider()
st.subheader("â‘£ ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")
competencies = ["ë¬¸ì œì •ì˜", "ë°ì´í„°/ì§€í‘œ", "ì‹¤í–‰ë ¥/ì£¼ë„ì„±", "í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "ê³ ê°ê°€ì¹˜"]

def compute_competency_df(hist):
    rows = []
    for h in hist:
        if h.get("competencies") and len(h["competencies"]) == 5:
            rows.append(h["competencies"])
    if not rows:
        return None
    df = pd.DataFrame(rows, columns=competencies)
    return df

comp_df = compute_competency_df(st.session_state.history)
if comp_df is not None:
    avg_scores = comp_df.mean().values.tolist()
    # Radar
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=avg_scores + [avg_scores[0]],
        theta=competencies + [competencies[0]],
        fill='toself',
        name='í‰ê·  ì ìˆ˜(0~5)'
    ))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,5])), showlegend=False, height=420)
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(comp_df, use_container_width=True)
else:
    st.info("ì•„ì§ ì—­ëŸ‰ ì ìˆ˜ë¥¼ íŒŒì‹±í•  ìˆ˜ ìˆëŠ” ì½”ì¹­ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì½”ì¹­ ì‹¤í–‰ ì‹œ ìë™ ìˆ˜ì§‘)")

# =========================
# ì„¸ì…˜ ë¦¬í¬íŠ¸ (CSV)
# =========================
st.divider()
st.subheader("â‘¤ ì„¸ì…˜ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (CSV)")

def build_report_df(hist):
    out = []
    for h in hist:
        row = {
            "timestamp": h.get("ts"),
            "question": h.get("question"),
            "user_answer": h.get("user_answer"),
            "score": h.get("score"),
            "feedback_raw": h.get("feedback")
        }
        comps = h.get("competencies")
        if comps and len(comps) == 5:
            for k, v in zip(competencies, comps):
                row[f"comp_{k}"] = v
        # ê°„ë‹¨íˆ ê·¼ê±° í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ë§Œ ë¬¶ì–´ì„œ ê¸°ë¡
        sups = h.get("supports") or []
        row["supports_preview"] = " || ".join([s[2][:120].replace("\n"," ") for s in sups])
        out.append(row)
    if not out:
        return pd.DataFrame(columns=["timestamp","question","user_answer","score","feedback_raw","supports_preview"])
    return pd.DataFrame(out)

report_df = build_report_df(st.session_state.history)
csv_bytes = report_df.to_csv(index=False).encode("utf-8-sig")
st.download_button("CSVë¡œ ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="interview_session_report.csv", mime="text/csv")

# =========================
# í‘¸í„°
# =========================
st.caption("Tip: íšŒì‚¬ JSONê³¼ ë¬¸ì„œë¥¼ í’ë¶€í•˜ê²Œ ë„£ì„ìˆ˜ë¡ ì§ˆë¬¸/ì½”ì¹­ì˜ íšŒì‚¬ ì •í•©ì„±ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤. (RAG ê·¼ê±°ëŠ” ìƒë‹¨ì—ì„œ í™•ì¸ ê°€ëŠ¥)")
