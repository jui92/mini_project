# -*- coding: utf-8 -*-
import os, re, json, urllib.parse
from typing import Optional, Tuple, Dict, List

import requests
from bs4 import BeautifulSoup
import html2text
import streamlit as st

# ============== ê¸°ë³¸ ì„¤ì • ==============
st.set_page_config(page_title="ì±„ìš© ê³µê³  íŒŒì„œ + LLM ì •ì œ", page_icon="ğŸ§¾", layout="wide")
st.title("ì±„ìš© ê³µê³  íŒŒì„œ Â· URL â†’ ì›ë¬¸ ìˆ˜ì§‘ â†’ LLM ì •ì œ ì¶œë ¥")

# ============== OpenAI ì¤€ë¹„ ==============
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

CHAT_MODEL = st.sidebar.selectbox("LLM ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)

# ============== HTTP ìœ í‹¸ ==============
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def http_get(url: str, timeout: int = 12) -> Optional[requests.Response]:
    try:
        r = requests.get(
            url,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                "Accept-Language": "ko, en;q=0.9",
            },
            timeout=timeout,
        )
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

# ============== ì›ë¬¸ ìˆ˜ì§‘ (Jina â†’ Web â†’ BS4) ==============
def fetch_jina_text(url: str, timeout: int = 15) -> str:
    try:
        parts = urllib.parse.urlsplit(url)
        prox = f"https://r.jina.ai/http://{parts.netloc}{parts.path}"
        if parts.query: prox += f"?{parts.query}"
        r = http_get(prox, timeout=timeout)
        return r.text.strip() if r else ""
    except Exception:
        return ""

def html_to_text(html_str: str) -> str:
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    txt = conv.handle(html_str)
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()

def fetch_webbase_text(url: str) -> str:
    r = http_get(url, timeout=12)
    if not r: return ""
    return html_to_text(r.text)

def fetch_bs4_text(url: str) -> Tuple[str, Optional[BeautifulSoup]]:
    r = http_get(url, timeout=12)
    if not r: return "", None
    soup = BeautifulSoup(r.text, "lxml")
    blocks = []
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True)
            if txt and len(txt) > 300:
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    if not blocks:
        return soup.get_text(" ", strip=True)[:120000], soup
    seen, out = set(), []
    for b in blocks:
        if b not in seen:
            seen.add(b); out.append(b)
    return ("\n\n".join(out)[:120000], soup)

def fetch_all_text(url: str):
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None
    jina = fetch_jina_text(url)
    if jina:
        _, soup = fetch_bs4_text(url)
        return jina, {"source":"jina","len":len(jina),"url_final":url}, soup
    web = fetch_webbase_text(url)
    if web:
        _, soup = fetch_bs4_text(url)
        return web, {"source":"webbase","len":len(web),"url_final":url}, soup
    bs, soup = fetch_bs4_text(url)
    return bs, {"source":"bs4","len":len(bs),"url_final":url}, soup

# ============== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ(LLM íŒíŠ¸ìš©) ==============
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    cand = []
    og = soup.find("meta", {"property":"og:site_name"})
    if og and og.get("content"): cand.append(og["content"])
    app = soup.find("meta", {"name":"application-name"})
    if app and app.get("content"): cand.append(app["content"])
    if soup.title and soup.title.string: cand.append(soup.title.string)
    cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
    cand = [c for c in cand if 2 <= len(c) <= 40]
    meta["company_name"] = cand[0] if cand else ""
    md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
    if md and md.get("content"):
        meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
    jt = ""
    ogt = soup.find("meta", {"property":"og:title"})
    if ogt and ogt.get("content"): jt = ogt["content"]
    if not jt:
        h1 = soup.find("h1")
        if h1 and h1.get_text(): jt = h1.get_text(strip=True)
    if not jt:
        h2 = soup.find("h2")
        if h2 and h2.get_text(): jt = h2.get_text(strip=True)
    meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    return meta

# ============== LLM ì •ì œ (í•µì‹¬) ==============
PROMPT_SYSTEM = (
    "ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
    "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
    "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼."
)

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    # ì»¨í…ìŠ¤íŠ¸ ê³¼ë‹¤ ë°©ì§€
    ctx = raw_text.strip()
    if len(ctx) > 9000:
        ctx = ctx[:9000]

    user_msg = {
        "role": "user",
        "content": (
            "ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
            "--- ì›ë¬¸ ì‹œì‘ ---\n"
            f"{ctx}\n"
            "--- ì›ë¬¸ ë ---\n\n"
            "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
            "{"
            "\"company_name\": str, "
            "\"company_intro\": str, "
            "\"job_title\": str, "
            "\"responsibilities\": [str], "
            "\"qualifications\": [str], "
            "\"preferences\": [str]"
            "}"
        ),
    }

    try:
        resp = client.chat.completions.create(
            model=model,
            temperature=0.2,
            response_format={"type": "json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM}, user_msg],
        )
        data = json.loads(resp.choices[0].message.content)
        # ë°©ì–´ì  í›„ì²˜ë¦¬
        for k in ["responsibilities","qualifications","preferences"]:
            if not isinstance(data.get(k, []), list):
                data[k] = []
            clean = []
            seen = set()
            for it in data[k]:
                t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·").strip()
                if t and t not in seen:
                    seen.add(t); clean.append(t)
            data[k] = clean[:12]
        for k in ["company_name","company_intro","job_title"]:
            if k in data and isinstance(data[k], str):
                data[k] = re.sub(r"\s+"," ", data[k]).strip()
        return data
    except Exception as e:
        return {
            "company_name": meta_hint.get("company_name",""),
            "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
            "job_title": meta_hint.get("job_title",""),
            "responsibilities": [],
            "qualifications": [],
            "preferences": [],
            "error": str(e),
        }

# ============== UI ==============
st.header("1) ì±„ìš© ê³µê³  URL")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì˜ˆ: https://www.wanted.co.kr/wd/123456")
run = st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ LLM ì •ì œ", type="primary")

if run:
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    with st.spinner("ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
        raw, meta, soup = fetch_all_text(url)
        hint = extract_company_meta(soup)

    with st.expander("ë””ë²„ê·¸: ìˆ˜ì§‘ ë©”íƒ€/íŒíŠ¸", expanded=False):
        st.json({"fetch_meta": meta, "meta_hint": hint})

    if not raw:
        st.error("ì›ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸/ë™ì  ë Œë”ë§/ë´‡ ì°¨ë‹¨ ê°€ëŠ¥)")
        st.stop()

    with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
        clean = llm_structurize(raw, hint, CHAT_MODEL)

    st.header("2) ì •ì œëœ íšŒì‚¬ ìš”ì•½ / ì±„ìš© ìš”ê±´")
    st.markdown("### íšŒì‚¬ëª…")
    st.write(clean.get("company_name") or "N/A")

    st.markdown("### ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½)")
    st.write(clean.get("company_intro") or "N/A")

    st.markdown("### ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…)")
    st.write(clean.get("job_title") or "N/A")

    st.markdown("### ì£¼ìš” ì—…ë¬´")
    resp = clean.get("responsibilities", [])
    if resp:
        for b in resp: st.markdown(f"- {b}")
    else:
        st.write("â€”")

    st.markdown("### ìê²© ìš”ê±´")
    qual = clean.get("qualifications", [])
    if qual:
        for b in qual: st.markdown(f"- {b}")
    else:
        st.write("â€”")

    st.markdown("### ìš°ëŒ€ ì‚¬í•­")
    pref = clean.get("preferences", [])
    if pref:
        for b in pref: st.markdown(f"- {b}")
    else:
        st.write("â€”")

    st.divider()
    st.subheader("ë‹¤ìš´ë¡œë“œ")
    st.download_button("ì›ë¬¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ", data=raw.encode("utf-8"),
                       file_name="job_posting_raw.txt", mime="text/plain")
    st.download_button("ì •ì œ ê²°ê³¼(JSON) ë‹¤ìš´ë¡œë“œ",
                       data=json.dumps(clean, ensure_ascii=False, indent=2).encode("utf-8"),
                       file_name="job_posting_clean.json", mime="application/json")

st.caption("íŒ) â€˜ìƒì„¸ ë”ë³´ê¸°â€™ê°€ í•„ìš”í•œ í˜ì´ì§€ëŠ” Jina í”„ë¡ì‹œë¥¼ ìš°ì„  ì‚¬ìš©í•˜ì—¬ ìµœëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.")
