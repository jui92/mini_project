{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9012f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n",
      "Using 240 files for training.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Using 60 files for validation.\n",
      "Found 60 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "IMG_SIZE = (28, 28)\n",
    "BATCH = 64\n",
    "\n",
    "root = Path(\"data\")\n",
    "train_root = root / \"train\"\n",
    "test_root  = root / \"test\"\n",
    "\n",
    "# train / val (train에서 20%를 검증으로)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root,\n",
    "    validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root,\n",
    "    validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "\n",
    "# test는 train의 class_names 순서를 그대로 사용해서 라벨 정렬 문제 예방\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, shuffle=False, label_mode=\"int\",\n",
    "    class_names=train_ds.class_names\n",
    ")\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)\n",
    "num_classes = len(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefa8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 28, 28, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_contrast (RandomCon  (None, 28, 28, 3)         0         \n",
      " trast)                                                          \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 48)        1344      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 48)        192       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 48)        20784     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 48)        192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 48)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 48)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 96)        41568     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 96)        83040     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 96)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 96)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 160)         138400    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 7, 7, 160)         640       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 160)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                15456     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 291       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302675 (1.15 MB)\n",
      "Trainable params: 301779 (1.15 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))  # RGB\n",
    "x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "x = layers.RandomRotation(0.08)(x)\n",
    "x = layers.RandomZoom(0.10)(x)\n",
    "x = layers.RandomContrast(0.10)(x)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "# Block 1\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.30)(x)\n",
    "\n",
    "# Block 3\n",
    "x = layers.Conv2D(160, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(96, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.35)(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cf0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 333ms/step - loss: 0.8788 - accuracy: 0.5667 - val_loss: 1.0861 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5487 - accuracy: 0.7375 - val_loss: 1.0919 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.3594 - accuracy: 0.8792 - val_loss: 1.2046 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9458\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.2160 - accuracy: 0.9458 - val_loss: 1.4700 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.1295 - accuracy: 0.9833 - val_loss: 1.8697 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.0920 - accuracy: 0.9875 - val_loss: 2.3897 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9875\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0625 - accuracy: 0.9875 - val_loss: 2.9316 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 3.3768 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0377 - accuracy: 0.9917 - val_loss: 3.7779 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9958\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.0275 - accuracy: 0.9958 - val_loss: 4.1734 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 4.5226 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0260 - accuracy: 0.9958 - val_loss: 4.8849 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 5.2364 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 5.5568 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.0340 - accuracy: 0.9958 - val_loss: 5.8612 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 6.1507 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 6.4237 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 6.6888 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9958\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0265 - accuracy: 0.9958 - val_loss: 6.9539 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 7.2060 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 7.4479 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9958\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 7.6910 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 7.9137 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 8.1325 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 8.3455 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 8.5510 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 8.7452 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 8.9311 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 9.1147 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0232 - accuracy: 0.9958 - val_loss: 9.2961 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0251 - accuracy: 0.9958 - val_loss: 9.4731 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.0320 - accuracy: 0.9917 - val_loss: 9.6383 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 9.7945 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 9.9513 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 10.1070 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 10.2590 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 10.4066 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 10.5504 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 10.6819 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 10.8092 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 10.9327 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 11.0580 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 11.1668 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 11.2726 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 11.3736 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0221 - accuracy: 0.9958 - val_loss: 11.4692 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 11.5611 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 11.6537 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 11.7423 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 11.8118 - val_accuracy: 0.3667 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "ckpt = keras.callbacks.ModelCheckpoint(filepath=\"best.weights.h5\", monitor=\"val_accuracy\", mode=\"max\",\n",
    "                                       save_best_only=True, save_weights_only=True)\n",
    "\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1812fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[ 0 20  0]\n",
      " [ 0 20  0]\n",
      " [ 0 20  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.0000    0.0000    0.0000        20\n",
      "        rock     0.3333    1.0000    0.5000        20\n",
      "     scissor     0.0000    0.0000    0.0000        20\n",
      "\n",
      "    accuracy                         0.3333        60\n",
      "   macro avg     0.1111    0.3333    0.1667        60\n",
      "weighted avg     0.1111    0.3333    0.1667        60\n",
      "\n",
      "\n",
      "[Test] loss=12.3682  acc=0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_opt = test_ds.cache()\n",
    "\n",
    "# 예측\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "# loss / accuracy\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a1694",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86add365",
   "metadata": {},
   "source": [
    "### 2nd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6c8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small-set max acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 소량 샘플로 과적합 테스트\n",
    "small_train = train_ds.unbatch().take(60).batch(32)   \n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "hist_small = model.fit(small_train, epochs=30, verbose=0)\n",
    "\n",
    "print(\"small-set max acc:\", max(hist_small.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84092b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 1.0, 1: 1.0256410256410255, 2: 0.975609756097561}\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 332ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 17.2735 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 18.1438 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 18.6724 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9958\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0085 - accuracy: 0.9958 - val_loss: 19.0903 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 18.7974 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 18.4689 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 18.0877 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 17.6410 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0041 - accuracy: 0.9958 - val_loss: 17.0398 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0062 - accuracy: 0.9958 - val_loss: 16.4058 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 8.7017e-04 - accuracy: 1.0000 - val_loss: 15.7511 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 15.1612 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 14.6762 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 14.3078 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 13.9568 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 4.7757e-04 - accuracy: 1.0000 - val_loss: 13.6689 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 8.3185e-04 - accuracy: 1.0000 - val_loss: 13.3732 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0048 - accuracy: 0.9958 - val_loss: 13.2227 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 5.2807e-04 - accuracy: 1.0000 - val_loss: 12.9643 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 5.0920e-04 - accuracy: 1.0000 - val_loss: 12.6685 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 8.2175e-04 - accuracy: 1.0000 - val_loss: 12.3179 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 11.9742 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 6.3205e-04 - accuracy: 1.0000 - val_loss: 11.5989 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 7.4645e-04 - accuracy: 1.0000 - val_loss: 11.2005 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 4.0045e-04 - accuracy: 1.0000 - val_loss: 10.8118 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 3.4982e-04 - accuracy: 1.0000 - val_loss: 10.3843 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 5.3481e-04 - accuracy: 1.0000 - val_loss: 9.9997 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 3.9129e-04 - accuracy: 1.0000 - val_loss: 9.6023 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 7.1340e-04 - accuracy: 1.0000 - val_loss: 9.1808 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 7.2815e-04 - accuracy: 1.0000 - val_loss: 8.7450 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.3259 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 7.8892 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 3.7123e-04 - accuracy: 1.0000 - val_loss: 7.4421 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.9555 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 6.6450e-04 - accuracy: 1.0000 - val_loss: 6.4561 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.9920 - val_accuracy: 0.3833 - lr: 7.5000e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 5.5166e-04 - accuracy: 1.0000 - val_loss: 5.5632 - val_accuracy: 0.4000 - lr: 7.5000e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 5.8020e-04 - accuracy: 1.0000 - val_loss: 5.1306 - val_accuracy: 0.4333 - lr: 7.5000e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7114 - val_accuracy: 0.5000 - lr: 7.5000e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 4.9138e-04 - accuracy: 1.0000 - val_loss: 4.3630 - val_accuracy: 0.5167 - lr: 7.5000e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 4.9546e-04 - accuracy: 1.0000 - val_loss: 4.0643 - val_accuracy: 0.5833 - lr: 7.5000e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 3.5191e-04 - accuracy: 1.0000 - val_loss: 3.7934 - val_accuracy: 0.5833 - lr: 7.5000e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 6.3622e-04 - accuracy: 1.0000 - val_loss: 3.5285 - val_accuracy: 0.6167 - lr: 7.5000e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 4.0213e-04 - accuracy: 1.0000 - val_loss: 3.2993 - val_accuracy: 0.6500 - lr: 7.5000e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 6.2084e-04 - accuracy: 1.0000 - val_loss: 3.0546 - val_accuracy: 0.6667 - lr: 7.5000e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 2.5448e-04 - accuracy: 1.0000 - val_loss: 2.7816 - val_accuracy: 0.6667 - lr: 7.5000e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4954 - val_accuracy: 0.6667 - lr: 7.5000e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.6833 - lr: 7.5000e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 5.8277e-04 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.6833 - lr: 7.5000e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 5.4232e-04 - accuracy: 1.0000 - val_loss: 1.8964 - val_accuracy: 0.6833 - lr: 7.5000e-05\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 학습률 낮추기\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 클래스 가중치\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for _, yb in train_ds.unbatch():\n",
    "    cnt[int(yb.numpy())] += 1\n",
    "K = len(train_ds.class_names); total = sum(cnt.values())\n",
    "class_weight = {i: total/(K*cnt.get(i,1)) for i in range(K)}\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "# 체크포인트(가중치만 저장) + Plateau\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50,\n",
    "                    callbacks=[ckpt, plateau], class_weight=class_weight, verbose=1)\n",
    "\n",
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2051d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[ 0 20  0]\n",
      " [ 0 20  0]\n",
      " [ 0 20  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.0000    0.0000    0.0000        20\n",
      "        rock     0.3333    1.0000    0.5000        20\n",
      "     scissor     0.0000    0.0000    0.0000        20\n",
      "\n",
      "    accuracy                         0.3333        60\n",
      "   macro avg     0.1111    0.3333    0.1667        60\n",
      "weighted avg     0.1111    0.3333    0.1667        60\n",
      "\n",
      "\n",
      "[Test] loss=4.1472  acc=0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "\n",
    "# 예측\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "# loss / accuracy\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ec8cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c3106",
   "metadata": {},
   "source": [
    "### 3rd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4742abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 323ms/step - loss: 0.3832 - accuracy: 0.8542 - val_loss: 4.2380 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.1615 - accuracy: 0.9333 - val_loss: 4.0733 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.1096 - accuracy: 0.9625 - val_loss: 5.7267 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.1015 - accuracy: 0.9625 - val_loss: 5.0762 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9750\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.0591 - accuracy: 0.9750 - val_loss: 11.1005 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 14.4130 - val_accuracy: 0.3333 - lr: 1.5000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.0532 - accuracy: 0.9792 - val_loss: 16.8763 - val_accuracy: 0.3333 - lr: 1.5000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9875\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.0584 - accuracy: 0.9875 - val_loss: 17.3487 - val_accuracy: 0.3333 - lr: 1.5000e-04\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 16.5216 - val_accuracy: 0.3333 - lr: 7.5000e-05\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0356 - accuracy: 0.9917 - val_loss: 15.7072 - val_accuracy: 0.3333 - lr: 7.5000e-05\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9917\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.0333 - accuracy: 0.9917 - val_loss: 15.4784 - val_accuracy: 0.3333 - lr: 7.5000e-05\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 15.8553 - val_accuracy: 0.3333 - lr: 3.7500e-05\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 16.3640 - val_accuracy: 0.3333 - lr: 3.7500e-05\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9958\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.0288 - accuracy: 0.9958 - val_loss: 17.0934 - val_accuracy: 0.3333 - lr: 3.7500e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 17.8356 - val_accuracy: 0.3333 - lr: 1.8750e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 18.5698 - val_accuracy: 0.3333 - lr: 1.8750e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9792\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0483 - accuracy: 0.9792 - val_loss: 19.2308 - val_accuracy: 0.3333 - lr: 1.8750e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 19.9639 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 20.7025 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 21.4219 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.0276 - accuracy: 0.9958 - val_loss: 22.1718 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0249 - accuracy: 0.9958 - val_loss: 22.9501 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0384 - accuracy: 0.9792 - val_loss: 23.6850 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0300 - accuracy: 0.9958 - val_loss: 24.4087 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0460 - accuracy: 0.9875 - val_loss: 25.1371 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 25.9699 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0495 - accuracy: 0.9875 - val_loss: 26.8155 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 27.6984 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 28.5833 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 29.3990 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 30.3265 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0208 - accuracy: 0.9958 - val_loss: 31.3877 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 32.5585 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 33.7649 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 35.1024 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0332 - accuracy: 0.9833 - val_loss: 36.4371 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0318 - accuracy: 0.9958 - val_loss: 37.7677 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 39.2139 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0272 - accuracy: 0.9875 - val_loss: 40.6782 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 42.0283 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 43.4963 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 44.9288 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 46.3267 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 47.6097 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 49.0143 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 50.4772 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 51.9690 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 53.5569 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.0232 - accuracy: 0.9958 - val_loss: 55.1263 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 56.7077 - val_accuracy: 0.3333 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# 증강 정의 \n",
    "aug = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                        layers.RandomRotation(0.05),\n",
    "                        layers.RandomZoom(0.08),\n",
    "                        layers.RandomContrast(0.05)])\n",
    "\n",
    "# 기존 모델을 백본으로 래핑\n",
    "backbone = model                       \n",
    "inputs = keras.Input(shape=(28, 28, 3))\n",
    "x = aug(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "outputs = backbone(x)                  \n",
    "model = keras.Model(inputs, outputs)   \n",
    "\n",
    "# 재컴파일 \n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50,\n",
    "                    callbacks=[ckpt, plateau],\n",
    "                    class_weight=class_weight,\n",
    "                    verbose=1)\n",
    "\n",
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17baacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[20  0  0]\n",
      " [20  0  0]\n",
      " [20  0  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.3333    1.0000    0.5000        20\n",
      "        rock     0.0000    0.0000    0.0000        20\n",
      "     scissor     0.0000    0.0000    0.0000        20\n",
      "\n",
      "    accuracy                         0.3333        60\n",
      "   macro avg     0.1111    0.3333    0.1667        60\n",
      "weighted avg     0.1111    0.3333    0.1667        60\n",
      "\n",
      "\n",
      "[Test] loss=4.0932  acc=0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "\n",
    "# 예측\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "# loss / accuracy\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559b538",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a9b67",
   "metadata": {},
   "source": [
    "### 4th 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc25bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n",
      "Using 240 files for training.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Using 60 files for validation.\n",
      "Found 60 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "IMG_SIZE = (160, 160)  \n",
    "BATCH = 64\n",
    "\n",
    "train_root = Path(\"data\") / \"train\"\n",
    "test_root  = Path(\"data\") / \"test\"\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root, image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    shuffle=False, label_mode=\"int\", class_names=train_ds.class_names)\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ddb7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 10s 1us/step\n",
      "Epoch 1/8\n",
      "4/4 [==============================] - 14s 2s/step - loss: 1.2114 - accuracy: 0.4000 - val_loss: 0.9171 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.9008 - accuracy: 0.5875 - val_loss: 0.7219 - val_accuracy: 0.7833 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7210 - accuracy: 0.7792 - val_loss: 0.5379 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5581 - accuracy: 0.8833 - val_loss: 0.4093 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3911 - accuracy: 0.9708 - val_loss: 0.3198 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3246 - accuracy: 0.9875 - val_loss: 0.2534 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.2587 - accuracy: 0.9958 - val_loss: 0.2084 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2191 - accuracy: 0.9917 - val_loss: 0.1774 - val_accuracy: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "# 가벼운 증강 \n",
    "augment = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.08),\n",
    "    layers.RandomContrast(0.05),\n",
    "], name=\"augment\")\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\",\n",
    "                      input_shape=IMG_SIZE + (3,))\n",
    "base.trainable = False   \n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = augment(inputs)\n",
    "x = preprocess_input(x)             \n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=8,\n",
    "                    callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c598fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[ 3  0 17]\n",
      " [ 0 19  1]\n",
      " [ 0  0 20]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     1.0000    0.1500    0.2609        20\n",
      "        rock     1.0000    0.9500    0.9744        20\n",
      "     scissor     0.5263    1.0000    0.6897        20\n",
      "\n",
      "    accuracy                         0.7000        60\n",
      "   macro avg     0.8421    0.7000    0.6416        60\n",
      "weighted avg     0.8421    0.7000    0.6416        60\n",
      "\n",
      "\n",
      "[Test] loss=0.5179  acc=0.7000\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present,\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
