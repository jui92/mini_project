{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9012f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n",
      "Using 240 files for training.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Using 60 files for validation.\n",
      "Found 60 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "IMG_SIZE = (28, 28)\n",
    "BATCH = 64\n",
    "\n",
    "root = Path(\"data\")\n",
    "train_root = root / \"train\"\n",
    "test_root  = root / \"test\"\n",
    "\n",
    "# train / val (train에서 20%를 검증으로)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root,\n",
    "    validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root,\n",
    "    validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "\n",
    "# test는 train의 class_names 순서를 그대로 사용해서 라벨 정렬 문제 예방\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, shuffle=False, label_mode=\"int\",\n",
    "    class_names=train_ds.class_names\n",
    ")\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)\n",
    "num_classes = len(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefa8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 28, 28, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_contrast (RandomCon  (None, 28, 28, 3)         0         \n",
      " trast)                                                          \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 48)        1344      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 48)        192       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 48)        20784     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 48)        192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 48)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 48)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 96)        41568     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 96)        83040     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 96)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 96)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 160)         138400    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 7, 7, 160)         640       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 160)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                15456     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 291       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302675 (1.15 MB)\n",
      "Trainable params: 301779 (1.15 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))  # RGB\n",
    "x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "x = layers.RandomRotation(0.08)(x)\n",
    "x = layers.RandomZoom(0.10)(x)\n",
    "x = layers.RandomContrast(0.10)(x)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "# Block 1\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.30)(x)\n",
    "\n",
    "# Block 3\n",
    "x = layers.Conv2D(160, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(96, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.35)(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cf0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 330ms/step - loss: 0.8660 - accuracy: 0.6000 - val_loss: 1.0838 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.5430 - accuracy: 0.8000 - val_loss: 1.0980 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.3499 - accuracy: 0.8625 - val_loss: 1.1678 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9750\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.1945 - accuracy: 0.9750 - val_loss: 1.4389 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.1268 - accuracy: 0.9625 - val_loss: 1.8156 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0916 - accuracy: 0.9625 - val_loss: 2.2492 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9750\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 2.7164 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 3.1078 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.0417 - accuracy: 0.9958 - val_loss: 3.4519 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9958\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.0352 - accuracy: 0.9958 - val_loss: 3.8083 - val_accuracy: 0.3667 - lr: 2.5000e-04\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.0291 - accuracy: 0.9958 - val_loss: 4.1283 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.0275 - accuracy: 0.9958 - val_loss: 4.4392 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 4.7246 - val_accuracy: 0.3667 - lr: 1.2500e-04\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 4.9661 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.0303 - accuracy: 0.9958 - val_loss: 5.1749 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 5.3594 - val_accuracy: 0.3667 - lr: 6.2500e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 5.5243 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 5.6793 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9958\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.0276 - accuracy: 0.9958 - val_loss: 5.8327 - val_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 5.9627 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 6.0764 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9958\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0227 - accuracy: 0.9958 - val_loss: 6.1835 - val_accuracy: 0.3667 - lr: 1.5625e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 6.2808 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 6.3749 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 6.4522 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 6.5230 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 6.5909 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 6.6533 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 6.7089 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0208 - accuracy: 0.9958 - val_loss: 6.7570 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 6.7973 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0271 - accuracy: 0.9958 - val_loss: 6.8348 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 6.8748 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 6.9081 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 6.9337 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 6.9473 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 6.9546 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 6.9595 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 6.9728 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 6.9485 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 6.9548 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 6.9875 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 7.0298 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 7.0835 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 7.0954 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 7.1150 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 7.1574 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 7.2127 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 7.2399 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 7.2320 - val_accuracy: 0.3667 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "ckpt = keras.callbacks.ModelCheckpoint(filepath=\"best.weights.h5\", monitor=\"val_accuracy\", mode=\"max\",\n",
    "                                       save_best_only=True, save_weights_only=True)\n",
    "\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1812fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[ 0 20  0]\n",
      " [ 0 20  0]\n",
      " [ 0 20  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.0000    0.0000    0.0000        20\n",
      "        rock     0.3333    1.0000    0.5000        20\n",
      "     scissor     0.0000    0.0000    0.0000        20\n",
      "\n",
      "    accuracy                         0.3333        60\n",
      "   macro avg     0.1111    0.3333    0.1667        60\n",
      "weighted avg     0.1111    0.3333    0.1667        60\n",
      "\n",
      "\n",
      "[Test] loss=8.2081  acc=0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_opt = test_ds.cache()\n",
    "\n",
    "# 예측\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "# loss / accuracy\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a1694",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86add365",
   "metadata": {},
   "source": [
    "### 2nd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6c8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small-set max acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 소량 샘플로 과적합 테스트\n",
    "small_train = train_ds.unbatch().take(60).batch(32)   \n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "hist_small = model.fit(small_train, epochs=30, verbose=0)\n",
    "\n",
    "print(\"small-set max acc:\", max(hist_small.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84092b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 1.0, 1: 1.0256410256410255, 2: 0.975609756097561}\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 336ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 14.5375 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 16.0678 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 18.3081 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 18.4968 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 18.0226 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 8.1382e-04 - accuracy: 1.0000 - val_loss: 17.4480 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 16.9227 - val_accuracy: 0.3667 - lr: 1.5000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 16.3911 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 5.1814e-04 - accuracy: 1.0000 - val_loss: 15.8665 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 15.4899 - val_accuracy: 0.3667 - lr: 7.5000e-05\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 5.4818e-04 - accuracy: 1.0000 - val_loss: 15.0917 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 14.7006 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 4.8284e-04 - accuracy: 1.0000 - val_loss: 14.3424 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 5.7123e-04 - accuracy: 1.0000 - val_loss: 13.9719 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 13.6266 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 3.9772e-04 - accuracy: 1.0000 - val_loss: 13.2809 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 7.0197e-04 - accuracy: 1.0000 - val_loss: 12.9211 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 12.2685 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 5.8856e-04 - accuracy: 1.0000 - val_loss: 11.6795 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 3.6055e-04 - accuracy: 1.0000 - val_loss: 11.1595 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 5.0603e-04 - accuracy: 1.0000 - val_loss: 10.7065 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 4.2868e-04 - accuracy: 1.0000 - val_loss: 10.2682 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.9020 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 6.3784e-04 - accuracy: 1.0000 - val_loss: 9.5520 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 3.7200e-04 - accuracy: 1.0000 - val_loss: 9.2153 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.9321 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 4.6271e-04 - accuracy: 1.0000 - val_loss: 8.7346 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 288ms/step - loss: 5.2824e-04 - accuracy: 1.0000 - val_loss: 8.4330 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.1601 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 3.2658e-04 - accuracy: 1.0000 - val_loss: 7.9169 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 5.8540e-04 - accuracy: 1.0000 - val_loss: 7.6196 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 5.7089e-04 - accuracy: 1.0000 - val_loss: 7.3255 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 5.3129e-04 - accuracy: 1.0000 - val_loss: 7.0128 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 6.8636e-04 - accuracy: 1.0000 - val_loss: 6.6604 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 3.1570e-04 - accuracy: 1.0000 - val_loss: 6.2992 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 4.0590e-04 - accuracy: 1.0000 - val_loss: 5.9157 - val_accuracy: 0.3667 - lr: 3.7500e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 4.3149e-04 - accuracy: 1.0000 - val_loss: 5.5158 - val_accuracy: 0.3833 - lr: 3.7500e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 6.9847e-04 - accuracy: 1.0000 - val_loss: 5.0531 - val_accuracy: 0.4167 - lr: 3.7500e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 6.3477e-04 - accuracy: 1.0000 - val_loss: 4.5000 - val_accuracy: 0.4667 - lr: 3.7500e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 2.3291e-04 - accuracy: 1.0000 - val_loss: 4.0939 - val_accuracy: 0.5000 - lr: 3.7500e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 3.7786e-04 - accuracy: 1.0000 - val_loss: 3.7986 - val_accuracy: 0.5000 - lr: 3.7500e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 287ms/step - loss: 7.8674e-04 - accuracy: 1.0000 - val_loss: 3.5615 - val_accuracy: 0.6000 - lr: 3.7500e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 9.9047e-04 - accuracy: 1.0000 - val_loss: 3.3684 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 6.3961e-04 - accuracy: 1.0000 - val_loss: 3.2510 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 7.9239e-04 - accuracy: 1.0000 - val_loss: 3.1329 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 2.5074e-04 - accuracy: 1.0000 - val_loss: 3.0003 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 9.8159e-04 - accuracy: 1.0000 - val_loss: 2.8689 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 4.2584e-04 - accuracy: 1.0000 - val_loss: 2.7528 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 3.3415e-04 - accuracy: 1.0000 - val_loss: 2.6356 - val_accuracy: 0.6500 - lr: 3.7500e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 4.8612e-04 - accuracy: 1.0000 - val_loss: 2.5050 - val_accuracy: 0.6667 - lr: 3.7500e-05\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 학습률 낮추기\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 클래스 가중치\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for _, yb in train_ds.unbatch():\n",
    "    cnt[int(yb.numpy())] += 1\n",
    "K = len(train_ds.class_names); total = sum(cnt.values())\n",
    "class_weight = {i: total/(K*cnt.get(i,1)) for i in range(K)}\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "# 체크포인트(가중치만 저장) + Plateau\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50,\n",
    "                    callbacks=[ckpt, plateau], class_weight=class_weight, verbose=1)\n",
    "\n",
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2051d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[ 0 20  0]\n",
      " [ 0 20  0]\n",
      " [ 0  6 14]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.0000    0.0000    0.0000        20\n",
      "        rock     0.4348    1.0000    0.6061        20\n",
      "     scissor     1.0000    0.7000    0.8235        20\n",
      "\n",
      "    accuracy                         0.5667        60\n",
      "   macro avg     0.4783    0.5667    0.4765        60\n",
      "weighted avg     0.4783    0.5667    0.4765        60\n",
      "\n",
      "\n",
      "[Test] loss=3.5010  acc=0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ec8cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c3106",
   "metadata": {},
   "source": [
    "### 3rd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4742abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 354ms/step - loss: 0.2596 - accuracy: 0.9083 - val_loss: 4.3357 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.1604 - accuracy: 0.9500 - val_loss: 2.7060 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.0675 - accuracy: 0.9625 - val_loss: 2.4504 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.0595 - accuracy: 0.9833 - val_loss: 2.5891 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0378 - accuracy: 0.9833 - val_loss: 2.6775 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9792\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 3.0782 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.0370 - accuracy: 0.9833 - val_loss: 3.2324 - val_accuracy: 0.3000 - lr: 1.5000e-04\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 3.3526 - val_accuracy: 0.3000 - lr: 1.5000e-04\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9958\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 3.5143 - val_accuracy: 0.3000 - lr: 1.5000e-04\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0296 - accuracy: 0.9917 - val_loss: 3.6452 - val_accuracy: 0.3000 - lr: 7.5000e-05\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.7607 - val_accuracy: 0.3000 - lr: 7.5000e-05\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9917\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 3.8778 - val_accuracy: 0.3000 - lr: 7.5000e-05\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.0366 - accuracy: 0.9917 - val_loss: 3.9612 - val_accuracy: 0.3000 - lr: 3.7500e-05\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.0179 - accuracy: 0.9917 - val_loss: 4.0858 - val_accuracy: 0.3000 - lr: 3.7500e-05\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9958\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "4/4 [==============================] - 1s 295ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 4.2288 - val_accuracy: 0.3000 - lr: 3.7500e-05\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 4.3548 - val_accuracy: 0.3000 - lr: 1.8750e-05\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 292ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 4.4921 - val_accuracy: 0.3000 - lr: 1.8750e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9792\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 4.6209 - val_accuracy: 0.3000 - lr: 1.8750e-05\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 4.7099 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 4.8168 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 4.9429 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 5.0742 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 5.2121 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0323 - accuracy: 0.9875 - val_loss: 5.3598 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 5.5232 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.0193 - accuracy: 0.9917 - val_loss: 5.7160 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 5.9366 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 6.1893 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 6.4622 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 6.7568 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 7.0714 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0295 - accuracy: 0.9958 - val_loss: 7.4243 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 7.7778 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.0334 - accuracy: 0.9833 - val_loss: 8.1431 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 8.5538 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0204 - accuracy: 0.9958 - val_loss: 8.9430 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 9.3463 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.0326 - accuracy: 0.9833 - val_loss: 9.7677 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.0383 - accuracy: 0.9917 - val_loss: 10.1664 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 10.6556 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 11.1429 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 11.5559 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 11.9545 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 12.3385 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 12.7192 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 13.0075 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 13.2822 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 13.5575 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 13.8283 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0218 - accuracy: 0.9875 - val_loss: 14.0400 - val_accuracy: 0.3333 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# 증강 정의 \n",
    "aug = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                        layers.RandomRotation(0.05),\n",
    "                        layers.RandomZoom(0.08),\n",
    "                        layers.RandomContrast(0.05)])\n",
    "\n",
    "# 기존 모델을 백본으로 래핑\n",
    "backbone = model                       \n",
    "inputs = keras.Input(shape=(28, 28, 3))\n",
    "x = aug(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "outputs = backbone(x)                  \n",
    "model = keras.Model(inputs, outputs)   \n",
    "\n",
    "# 재컴파일 \n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[ckpt, plateau],\n",
    "                    class_weight=class_weight, verbose=1)\n",
    "\n",
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17baacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[20  0  0]\n",
      " [20  0  0]\n",
      " [20  0  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.3333    1.0000    0.5000        20\n",
      "        rock     0.0000    0.0000    0.0000        20\n",
      "     scissor     0.0000    0.0000    0.0000        20\n",
      "\n",
      "    accuracy                         0.3333        60\n",
      "   macro avg     0.1111    0.3333    0.1667        60\n",
      "weighted avg     0.1111    0.3333    0.1667        60\n",
      "\n",
      "\n",
      "[Test] loss=4.1049  acc=0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559b538",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a9b67",
   "metadata": {},
   "source": [
    "### 4th 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc25bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n",
      "Using 240 files for training.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Using 60 files for validation.\n",
      "Found 60 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (160, 160)  \n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root, image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    shuffle=False, label_mode=\"int\", class_names=train_ds.class_names)\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ddb7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4/4 [==============================] - 14s 2s/step - loss: 1.0498 - accuracy: 0.4500 - val_loss: 0.8205 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7890 - accuracy: 0.7583 - val_loss: 0.6126 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5922 - accuracy: 0.9500 - val_loss: 0.4520 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4455 - accuracy: 0.9792 - val_loss: 0.3436 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3604 - accuracy: 0.9750 - val_loss: 0.2732 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2735 - accuracy: 0.9958 - val_loss: 0.2234 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2184 - accuracy: 0.9917 - val_loss: 0.1860 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1843 - accuracy: 0.9917 - val_loss: 0.1565 - val_accuracy: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "augment = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                            layers.RandomRotation(0.05),\n",
    "                            layers.RandomZoom(0.08),\n",
    "                            layers.RandomContrast(0.05)], name=\"augment\")\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE + (3,))\n",
    "base.trainable = False   \n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = augment(inputs)\n",
    "x = preprocess_input(x)             \n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=8,\n",
    "                    callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c598fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[19  0  1]\n",
      " [ 0 20  0]\n",
      " [ 0  0 20]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     1.0000    0.9500    0.9744        20\n",
      "        rock     1.0000    1.0000    1.0000        20\n",
      "     scissor     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9833        60\n",
      "   macro avg     0.9841    0.9833    0.9833        60\n",
      "weighted avg     0.9841    0.9833    0.9833        60\n",
      "\n",
      "\n",
      "[Test] loss=0.3853  acc=0.9833\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present,\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
