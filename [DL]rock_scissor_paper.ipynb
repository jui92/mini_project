{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9012f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n",
      "Using 720 files for training.\n",
      "Found 900 files belonging to 3 classes.\n",
      "Using 180 files for validation.\n",
      "Found 150 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "IMG_SIZE = (28, 28)\n",
    "BATCH = 64\n",
    "\n",
    "root = Path(\"data\")\n",
    "train_root = root / \"train\"\n",
    "test_root  = root / \"test\"\n",
    "\n",
    "# train / val (train에서 20%를 검증으로)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\"\n",
    ")\n",
    "\n",
    "# test는 train의 class_names 순서를 그대로 사용해서 라벨 정렬 문제 예방\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root, image_size=IMG_SIZE, batch_size=BATCH, shuffle=False, label_mode=\"int\",\n",
    "    class_names=train_ds.class_names\n",
    ")\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)\n",
    "num_classes = len(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefa8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 28, 28, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " random_contrast (RandomCon  (None, 28, 28, 3)         0         \n",
      " trast)                                                          \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 28, 28, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 48)        1344      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 48)        192       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 48)        20784     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 48)        192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 48)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 48)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 96)        41568     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 96)        83040     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 96)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 96)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 160)         138400    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 7, 7, 160)         640       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 160)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                15456     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 291       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302675 (1.15 MB)\n",
      "Trainable params: 301779 (1.15 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))  \n",
    "x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "x = layers.RandomRotation(0.08)(x)\n",
    "x = layers.RandomZoom(0.10)(x)\n",
    "x = layers.RandomContrast(0.10)(x)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "# Block 1\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(48, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(96, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.30)(x)\n",
    "\n",
    "# Block 3\n",
    "x = layers.Conv2D(160, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(96, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.35)(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cf0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 237ms/step - loss: 0.8373 - accuracy: 0.6014 - val_loss: 1.1005 - val_accuracy: 0.3389 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 3s 204ms/step - loss: 0.4793 - accuracy: 0.7931 - val_loss: 1.1334 - val_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.3486 - accuracy: 0.8694 - val_loss: 1.2170 - val_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.8722\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.3248 - accuracy: 0.8722 - val_loss: 1.6621 - val_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 3s 219ms/step - loss: 0.2254 - accuracy: 0.9181 - val_loss: 2.6499 - val_accuracy: 0.3167 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.1879 - accuracy: 0.9292 - val_loss: 3.5411 - val_accuracy: 0.3167 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9431\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.1632 - accuracy: 0.9431 - val_loss: 5.2953 - val_accuracy: 0.3167 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 3s 216ms/step - loss: 0.1244 - accuracy: 0.9611 - val_loss: 5.9009 - val_accuracy: 0.3167 - lr: 2.5000e-04\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 3s 216ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 6.0922 - val_accuracy: 0.3167 - lr: 2.5000e-04\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9667\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.1127 - accuracy: 0.9667 - val_loss: 5.9662 - val_accuracy: 0.3167 - lr: 2.5000e-04\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 0.1122 - accuracy: 0.9639 - val_loss: 6.8387 - val_accuracy: 0.3167 - lr: 1.2500e-04\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 0.0917 - accuracy: 0.9736 - val_loss: 7.4781 - val_accuracy: 0.3167 - lr: 1.2500e-04\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9736\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.0944 - accuracy: 0.9736 - val_loss: 8.3618 - val_accuracy: 0.3167 - lr: 1.2500e-04\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.0985 - accuracy: 0.9667 - val_loss: 8.2900 - val_accuracy: 0.3167 - lr: 6.2500e-05\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 0.0817 - accuracy: 0.9764 - val_loss: 8.4217 - val_accuracy: 0.3167 - lr: 6.2500e-05\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9708\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.0824 - accuracy: 0.9708 - val_loss: 8.5809 - val_accuracy: 0.3167 - lr: 6.2500e-05\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 3s 209ms/step - loss: 0.0804 - accuracy: 0.9792 - val_loss: 8.9050 - val_accuracy: 0.3167 - lr: 3.1250e-05\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 3s 216ms/step - loss: 0.0771 - accuracy: 0.9792 - val_loss: 9.3524 - val_accuracy: 0.3167 - lr: 3.1250e-05\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9736\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 9.5548 - val_accuracy: 0.3167 - lr: 3.1250e-05\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.0726 - accuracy: 0.9792 - val_loss: 9.6226 - val_accuracy: 0.3167 - lr: 1.5625e-05\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 3s 199ms/step - loss: 0.0625 - accuracy: 0.9847 - val_loss: 9.6346 - val_accuracy: 0.3167 - lr: 1.5625e-05\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9764\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "12/12 [==============================] - 3s 202ms/step - loss: 0.0812 - accuracy: 0.9764 - val_loss: 9.7579 - val_accuracy: 0.3167 - lr: 1.5625e-05\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.0752 - accuracy: 0.9861 - val_loss: 9.7733 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 0.0703 - accuracy: 0.9778 - val_loss: 9.6877 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 3s 247ms/step - loss: 0.0717 - accuracy: 0.9792 - val_loss: 9.6269 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.0788 - accuracy: 0.9764 - val_loss: 9.5464 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 3s 222ms/step - loss: 0.0670 - accuracy: 0.9847 - val_loss: 9.3387 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 0.0714 - accuracy: 0.9764 - val_loss: 9.3397 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 9.0677 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 3s 217ms/step - loss: 0.0665 - accuracy: 0.9861 - val_loss: 8.6973 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 8.3425 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 3s 219ms/step - loss: 0.0789 - accuracy: 0.9778 - val_loss: 8.0233 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0762 - accuracy: 0.9806 - val_loss: 7.6032 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.0734 - accuracy: 0.9819 - val_loss: 7.1084 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0636 - accuracy: 0.9833 - val_loss: 6.6400 - val_accuracy: 0.3167 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 3s 221ms/step - loss: 0.0615 - accuracy: 0.9861 - val_loss: 6.1634 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0675 - accuracy: 0.9764 - val_loss: 5.6743 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 0.0792 - accuracy: 0.9778 - val_loss: 5.2160 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0551 - accuracy: 0.9819 - val_loss: 4.6993 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 3s 223ms/step - loss: 0.0733 - accuracy: 0.9792 - val_loss: 4.1766 - val_accuracy: 0.3500 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 0.0683 - accuracy: 0.9806 - val_loss: 3.6524 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 3s 219ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 3.0012 - val_accuracy: 0.4278 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.0732 - accuracy: 0.9792 - val_loss: 2.5931 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 3s 211ms/step - loss: 0.0561 - accuracy: 0.9833 - val_loss: 2.2146 - val_accuracy: 0.5167 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 3s 220ms/step - loss: 0.0676 - accuracy: 0.9806 - val_loss: 1.6983 - val_accuracy: 0.5722 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 3s 215ms/step - loss: 0.0557 - accuracy: 0.9861 - val_loss: 1.3861 - val_accuracy: 0.5944 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 0.0519 - accuracy: 0.9903 - val_loss: 1.2308 - val_accuracy: 0.6500 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 0.0682 - accuracy: 0.9778 - val_loss: 1.0570 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 3s 222ms/step - loss: 0.0602 - accuracy: 0.9861 - val_loss: 0.8838 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 0.0632 - accuracy: 0.9847 - val_loss: 0.7183 - val_accuracy: 0.7667 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "ckpt = keras.callbacks.ModelCheckpoint(filepath=\"best.weights.h5\", monitor=\"val_accuracy\", mode=\"max\",\n",
    "                                       save_best_only=True, save_weights_only=True)\n",
    "\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1812fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[50  0  0]\n",
      " [22 28  0]\n",
      " [50  0  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.4098    1.0000    0.5814        50\n",
      "        rock     1.0000    0.5600    0.7179        50\n",
      "     scissor     0.0000    0.0000    0.0000        50\n",
      "\n",
      "    accuracy                         0.5200       150\n",
      "   macro avg     0.4699    0.5200    0.4331       150\n",
      "weighted avg     0.4699    0.5200    0.4331       150\n",
      "\n",
      "\n",
      "[Test] loss=3.3746  acc=0.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_opt = test_ds.cache()\n",
    "\n",
    "# 예측\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "# loss / accuracy\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a1694",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86add365",
   "metadata": {},
   "source": [
    "### 2nd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6c8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small-set max acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 소량 샘플로 과적합 테스트\n",
    "small_train = train_ds.unbatch().take(60).batch(32)   \n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "hist_small = model.fit(small_train, epochs=30, verbose=0)\n",
    "\n",
    "print(\"small-set max acc:\", max(hist_small.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84092b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 1.00418410041841, 1: 1.0084033613445378, 2: 0.9876543209876543}\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 226ms/step - loss: 0.1024 - accuracy: 0.9625 - val_loss: 1.0864 - val_accuracy: 0.7389 - lr: 3.0000e-04\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 3s 204ms/step - loss: 0.0730 - accuracy: 0.9819 - val_loss: 1.0975 - val_accuracy: 0.7611 - lr: 3.0000e-04\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 0.0602 - accuracy: 0.9833 - val_loss: 0.5536 - val_accuracy: 0.8444 - lr: 3.0000e-04\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.0777 - accuracy: 0.9694 - val_loss: 1.0497 - val_accuracy: 0.6722 - lr: 3.0000e-04\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 0.0510 - accuracy: 0.9806 - val_loss: 1.9270 - val_accuracy: 0.5889 - lr: 3.0000e-04\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9819\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 2.8631 - val_accuracy: 0.5167 - lr: 3.0000e-04\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 3s 214ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 1.0082 - val_accuracy: 0.6833 - lr: 1.5000e-04\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 0.0443 - accuracy: 0.9889 - val_loss: 0.4773 - val_accuracy: 0.8333 - lr: 1.5000e-04\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.4364 - val_accuracy: 0.8500 - lr: 1.5000e-04\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 3s 211ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.2808 - val_accuracy: 0.8833 - lr: 1.5000e-04\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.1616 - val_accuracy: 0.9333 - lr: 1.5000e-04\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.0308 - accuracy: 0.9875 - val_loss: 0.2272 - val_accuracy: 0.9222 - lr: 1.5000e-04\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 3s 199ms/step - loss: 0.0391 - accuracy: 0.9903 - val_loss: 1.5085 - val_accuracy: 0.6056 - lr: 1.5000e-04\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9847\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "12/12 [==============================] - 3s 201ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.9480 - val_accuracy: 0.6944 - lr: 1.5000e-04\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 0.4440 - val_accuracy: 0.8556 - lr: 7.5000e-05\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0262 - accuracy: 0.9944 - val_loss: 0.3897 - val_accuracy: 0.8778 - lr: 7.5000e-05\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9917\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "12/12 [==============================] - 3s 202ms/step - loss: 0.0342 - accuracy: 0.9917 - val_loss: 0.3583 - val_accuracy: 0.8667 - lr: 7.5000e-05\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 3s 207ms/step - loss: 0.0311 - accuracy: 0.9958 - val_loss: 0.4651 - val_accuracy: 0.8222 - lr: 3.7500e-05\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 3s 199ms/step - loss: 0.0299 - accuracy: 0.9889 - val_loss: 0.4303 - val_accuracy: 0.8444 - lr: 3.7500e-05\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9958\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "12/12 [==============================] - 3s 201ms/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.3804 - val_accuracy: 0.8611 - lr: 3.7500e-05\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.3122 - val_accuracy: 0.8833 - lr: 1.8750e-05\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 0.0236 - accuracy: 0.9972 - val_loss: 0.2872 - val_accuracy: 0.8722 - lr: 1.8750e-05\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9931\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 0.0335 - accuracy: 0.9931 - val_loss: 0.2897 - val_accuracy: 0.8778 - lr: 1.8750e-05\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.2919 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.2845 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.3163 - val_accuracy: 0.8833 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 3s 216ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.2733 - val_accuracy: 0.8944 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 3s 222ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.2727 - val_accuracy: 0.9000 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.2923 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.3709 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.3629 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.3781 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 3s 204ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.3517 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 3s 214ms/step - loss: 0.0337 - accuracy: 0.9917 - val_loss: 0.3647 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.3812 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 3s 198ms/step - loss: 0.0397 - accuracy: 0.9875 - val_loss: 0.3979 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 3s 203ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.3798 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.4730 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 3s 202ms/step - loss: 0.0155 - accuracy: 0.9986 - val_loss: 0.5016 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 3s 198ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.4881 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 3s 204ms/step - loss: 0.0238 - accuracy: 0.9958 - val_loss: 0.4760 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 3s 198ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.4652 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.4696 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.4691 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.5743 - val_accuracy: 0.8056 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.5951 - val_accuracy: 0.7944 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 3s 199ms/step - loss: 0.0181 - accuracy: 0.9986 - val_loss: 0.5708 - val_accuracy: 0.7944 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 3s 201ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.5327 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 2s 196ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.4819 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 3s 196ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.4479 - val_accuracy: 0.8333 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 학습률 낮추기\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 클래스 가중치\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for _, yb in train_ds.unbatch():\n",
    "    cnt[int(yb.numpy())] += 1\n",
    "K = len(train_ds.class_names); total = sum(cnt.values())\n",
    "class_weight = {i: total/(K*cnt.get(i,1)) for i in range(K)}\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "# 체크포인트(가중치만 저장) + Plateau\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50,\n",
    "                    callbacks=[ckpt, plateau], class_weight=class_weight, verbose=1)\n",
    "\n",
    "model.load_weights(\"best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2051d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[31 19  0]\n",
      " [ 0 50  0]\n",
      " [19 31  0]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.6200    0.6200    0.6200        50\n",
      "        rock     0.5000    1.0000    0.6667        50\n",
      "     scissor     0.0000    0.0000    0.0000        50\n",
      "\n",
      "    accuracy                         0.5400       150\n",
      "   macro avg     0.3733    0.5400    0.4289       150\n",
      "weighted avg     0.3733    0.5400    0.4289       150\n",
      "\n",
      "\n",
      "[Test] loss=2.5470  acc=0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present, target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ec8cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c3106",
   "metadata": {},
   "source": [
    "### 3rd 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc25bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n",
      "Using 720 files for training.\n",
      "Found 900 files belonging to 3 classes.\n",
      "Using 180 files for validation.\n",
      "Found 150 files belonging to 3 classes.\n",
      "classes: ['paper', 'rock', 'scissor']\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (160, 160)  \n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_root, validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH, label_mode=\"int\")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_root, image_size=IMG_SIZE, batch_size=BATCH,\n",
    "    shuffle=False, label_mode=\"int\", class_names=train_ds.class_names)\n",
    "\n",
    "print(\"classes:\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ddb7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 21s 1s/step - loss: 0.8506 - accuracy: 0.6542 - val_loss: 0.5795 - val_accuracy: 0.9056 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.4943 - accuracy: 0.9194 - val_loss: 0.3850 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.3334 - accuracy: 0.9625 - val_loss: 0.2899 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2548 - accuracy: 0.9708 - val_loss: 0.2348 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.2124 - accuracy: 0.9722 - val_loss: 0.2001 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1735 - accuracy: 0.9806 - val_loss: 0.1753 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1511 - accuracy: 0.9861 - val_loss: 0.1542 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1345 - accuracy: 0.9889 - val_loss: 0.1391 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1199 - accuracy: 0.9847 - val_loss: 0.1283 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.1067 - accuracy: 0.9875 - val_loss: 0.1170 - val_accuracy: 0.9778 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "augment = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                            layers.RandomRotation(0.05),\n",
    "                            layers.RandomZoom(0.08),\n",
    "                            layers.RandomContrast(0.05)], name=\"augment\")\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE + (3,))\n",
    "base.trainable = False   \n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = augment(inputs)\n",
    "x = preprocess_input(x)             \n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\"best.weights.h5\", monitor=\"val_accuracy\",\n",
    "                                       mode=\"max\", save_best_only=True, save_weights_only=True)\n",
    "plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                                            patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
    "                    callbacks=[ckpt, plateau], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c598fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix (labels in order: [0 1 2] )\n",
      "[[50  0  0]\n",
      " [ 0 50  0]\n",
      " [ 1  0 49]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       paper     0.9804    1.0000    0.9901        50\n",
      "        rock     1.0000    1.0000    1.0000        50\n",
      "     scissor     1.0000    0.9800    0.9899        50\n",
      "\n",
      "    accuracy                         0.9933       150\n",
      "   macro avg     0.9935    0.9933    0.9933       150\n",
      "weighted avg     0.9935    0.9933    0.9933       150\n",
      "\n",
      "\n",
      "[Test] loss=0.1293  acc=0.9933\n"
     ]
    }
   ],
   "source": [
    "test_opt = test_ds.cache()\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_opt.unbatch().batch(4096)])\n",
    "y_pred = model.predict(test_opt, verbose=0).argmax(axis=1)\n",
    "present = np.array(sorted(np.unique(y_true)))\n",
    "target_names = [train_ds.class_names[i] for i in present]\n",
    "\n",
    "print(\"\\nConfusion matrix (labels in order:\", present, \")\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=present))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present,\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_opt, verbose=0)\n",
    "print(f\"\\n[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
