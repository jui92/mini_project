# app_ai4i_reporter.py
import os
import io
import time
import json
import requests
import joblib
import numpy as np
import pandas as pd
import streamlit as st

from typing import Tuple, List
from dataclasses import dataclass

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer

# -------------------------
# 0) ê¸°ë³¸ ì„¤ì •
# -------------------------
st.set_page_config(page_title="ì„¤ë¹„ ë¡œê·¸ â†’ ì§„ë‹¨ ë³´ê³ ì„œ ìë™ìƒì„±ê¸°", page_icon="ğŸ› ï¸", layout="wide")
st.title("ğŸ› ï¸ ì„¤ë¹„ ë¡œê·¸ â†’ ì§„ë‹¨ ë³´ê³ ì„œ ìë™ìƒì„±ê¸° (AI4I 2020 ê¸°ë°˜)")

AI4I_URL = "https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv"

OPENAI_KEY = os.getenv("OPENAI_API_KEY", None)
try:
    from openai import OpenAI
    openai_client = OpenAI(api_key=OPENAI_KEY) if OPENAI_KEY else None
except Exception:
    openai_client = None

MODEL_PATH = "artifacts/ai4i_rf.pkl"
STATS_PATH = "artifacts/ai4i_stats.json"
os.makedirs("artifacts", exist_ok=True)

TARGET_LABELS = ["Normal", "TWF", "HDF", "PWF", "OSF", "RNF"]

# -------------------------
# 1) ë°ì´í„° ë¡œë”©/ê°€ê³µ
# -------------------------
def download_ai4i() -> pd.DataFrame:
    r = requests.get(AI4I_URL, timeout=30)
    r.raise_for_status()
    df = pd.read_csv(io.StringIO(r.text))
    return df

def derive_failure_type(df: pd.DataFrame) -> pd.DataFrame:
    # AI4I ì»¬ëŸ¼ ê°€ì •: ['UDI','Product ID','Type','Air temperature [K]','Process temperature [K]',
    # 'Rotational speed [rpm]','Torque [Nm]','Tool wear [min]','Machine failure',
    # 'TWF','HDF','PWF','OSF','RNF']
    df = df.copy()
    def pick_failure(row):
        if row.get('Machine failure', 0) == 0:
            return "Normal"
        # ì—¬ëŸ¬ ê°œê°€ 1ì¼ ìˆ˜ ìˆì–´ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ë“ , ë‹¤ì¤‘ì´ë©´ ì²« ë²ˆì§¸ë¡œ íƒ1
        for k in ["TWF","HDF","PWF","OSF","RNF"]:
            if k in row and row[k] == 1:
                return k
        return "Normal"
    df["failure_type"] = df.apply(pick_failure, axis=1)
    return df

def split_features_target(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
    # ë¶„ë¥˜ì— ì‚¬ìš©í•  íŠ¹ì§• ì—´ ì„ íƒ
    feature_cols = [
        "Type",
        "Air temperature [K]",
        "Process temperature [K]",
        "Rotational speed [rpm]",
        "Torque [Nm]",
        "Tool wear [min]",
    ]
    X = df[feature_cols].copy()
    y = df["failure_type"].copy()
    return X, y

# -------------------------
# 2) í•™ìŠµ íŒŒì´í”„ë¼ì¸
# -------------------------
def build_pipeline(categorical_cols: List[str], numeric_cols: List[str]) -> Pipeline:
    cat_tf = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ohe", OneHotEncoder(handle_unknown="ignore"))
    ])
    num_tf = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])
    preproc = ColumnTransformer(
        transformers=[
            ("cat", cat_tf, categorical_cols),
            ("num", num_tf, numeric_cols)
        ]
    )
    clf = RandomForestClassifier(
        n_estimators=300,
        max_depth=None,
        class_weight="balanced_subsample",
        random_state=42,
        n_jobs=-1
    )
    pipe = Pipeline(steps=[("prep", preproc), ("clf", clf)])
    return pipe

def fit_and_save_model(df: pd.DataFrame):
    X, y = split_features_target(df)
    categorical_cols = ["Type"]
    numeric_cols = [c for c in X.columns if c not in categorical_cols]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )
    pipe = build_pipeline(categorical_cols, numeric_cols)
    pipe.fit(X_train, y_train)

    # ì„±ëŠ¥ ë³´ê³ 
    y_pred = pipe.predict(X_test)
    report = classification_report(y_test, y_pred, labels=TARGET_LABELS, zero_division=0, output_dict=False)
    cm = confusion_matrix(y_test, y_pred, labels=TARGET_LABELS)
    # í†µê³„(ë¶„ìœ„ìˆ˜) ì €ì¥: ë³´ê³ ì„œ ìƒì„± ì‹œ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¬ìš©
    stats = {
        "numeric_cols": numeric_cols,
        "quantiles": {c: {
            "q10": float(df[c].quantile(0.10)),
            "q50": float(df[c].quantile(0.50)),
            "q90": float(df[c].quantile(0.90)),
            "min": float(df[c].min()),
            "max": float(df[c].max())
        } for c in numeric_cols}
    }
    joblib.dump(pipe, MODEL_PATH)
    with open(STATS_PATH, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    return pipe, report, cm, stats

def load_model_and_stats():
    if os.path.exists(MODEL_PATH) and os.path.exists(STATS_PATH):
        pipe = joblib.load(MODEL_PATH)
        with open(STATS_PATH, "r", encoding="utf-8") as f:
            stats = json.load(f)
        return pipe, stats
    return None, None

# -------------------------
# 3) ë³´ê³ ì„œ ìƒì„±ê¸° (í…œí”Œë¦¿ / LLM ì„ íƒì )
# -------------------------
@dataclass
class PredictionResult:
    label: str
    proba: float
    probas: dict

def predict_row(pipe: Pipeline, row: dict) -> PredictionResult:
    df = pd.DataFrame([row])
    probs = pipe.predict_proba(df)[0]
    classes = list(pipe.classes_)
    idx = int(np.argmax(probs))
    return PredictionResult(
        label=classes[idx],
        proba=float(probs[idx]),
        probas={cls: float(p) for cls, p in zip(classes, probs)}
    )

def feature_flags(row: dict, stats: dict) -> List[str]:
    """ ì„¼ì„œê°’ì´ ë¶„ìœ„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒ/í•˜ìœ„ êµ¬ê°„ì— ìˆëŠ”ì§€ í”Œë˜ê·¸ ìƒì„± """
    flags = []
    q = stats["quantiles"]
    for c in stats["numeric_cols"]:
        v = row.get(c, None)
        if v is None: 
            continue
        q10, q90 = q[c]["q10"], q[c]["q90"]
        if v <= q10:
            flags.append(f"{c} ë‚®ìŒ(â‰¤p10)")
        elif v >= q90:
            flags.append(f"{c} ë†’ìŒ(â‰¥p90)")
    return flags

def template_report(row: dict, pred: PredictionResult, stats: dict) -> str:
    flags = feature_flags(row, stats)
    risk = "ë‚®ìŒ"
    if pred.label != "Normal":
        if pred.proba >= 0.8: risk = "ë§¤ìš° ë†’ìŒ"
        elif pred.proba >= 0.6: risk = "ë†’ìŒ"
        else: risk = "ì¤‘ê°„"
    bullets = "\n".join([f"- {f}" for f in flags]) or "- íŠ¹ì´ì¹˜ ì—†ìŒ"
    rec = {
        "TWF": "ê³µêµ¬ ë§ˆëª¨ ì ê²€ ë° êµì²´ ì£¼ê¸° ì¡°ì • ê¶Œì¥.",
        "HDF": "ëƒ‰ê°Â·ë°©ì—´ê³„í†µ ì ê²€(íŒ¬/ì—´êµí™˜ê¸°, ìœ¤í™œ/ëƒ‰ê°ìœ  ìƒíƒœ í™•ì¸).",
        "PWF": "ì „ì› í’ˆì§ˆ/ì „ë¥˜ í”¼í¬ ì ê²€, ì „ë ¥ê³„í†µ ë¡œê¹… ë¶„ì„.",
        "OSF": "ê¸°ê³„ì  ê³¼ë¶€í•˜/ì§„ë™ ìƒíƒœ ëª¨ë‹ˆí„°ë§, í•˜ì¤‘ ì¡°ê±´ ì¬ì„¤ì •.",
        "RNF": "ë¶ˆê·œì¹™ ê³ ì¥ íŒ¨í„´. ìµœê·¼ ì‘ì—…ì¡°ê±´/ì •ë¹„ì´ë ¥ êµì°¨ì ê²€.",
        "Normal": "ì¦‰ê° ì¡°ì¹˜ ë¶ˆí•„ìš”. ì¶”ì„¸ ëª¨ë‹ˆí„°ë§ ìœ ì§€."
    }[pred.label]
    return f"""### ì§„ë‹¨ ìš”ì•½
- ì˜ˆì¸¡ ìƒíƒœ: **{pred.label}** (ì‹ ë¢° {pred.proba:.2f})
- ìœ„í—˜ë„: **{risk}**

### ì„¼ì„œ íŠ¹ì´ì¹˜
{bullets}

### ê¶Œì¥ ì¡°ì¹˜
- {rec}

### í™•ë¥  ë¶„í¬
{json.dumps(pred.probas, ensure_ascii=False, indent=2)}
"""

def llm_report(row: dict, pred: PredictionResult, stats: dict) -> str:
    if openai_client is None:
        return template_report(row, pred, stats)
    sys = ("ë„ˆëŠ” ì‚°ì—… ì„¤ë¹„ ì§„ë‹¨ ë³´ê³ ì„œ ì‘ì„± ì „ë¬¸ê°€ë‹¤. ê°„ê²°í•œ í•œêµ­ì–´ë¡œ í•µì‹¬ë§Œ ì •ë¦¬í•˜ë¼. "
           "ê³¼ë„í•œ ë‹¨ì • ê¸ˆì§€. ìˆ«ìì™€ ì¶”ì •ì€ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ.")
    user = f"""
[ì„¼ì„œ ì…ë ¥]
{json.dumps(row, ensure_ascii=False, indent=2)}

[ëª¨ë¸ ì˜ˆì¸¡]
ë¼ë²¨: {pred.label}, ì‹ ë¢°: {pred.proba:.2f}
ë¶„í¬: {json.dumps(pred.probas, ensure_ascii=False)}

[ë°ì´í„° ë¶„ìœ„ìˆ˜ ê¸°ì¤€]
{json.dumps(stats['quantiles'], ensure_ascii=False)[:1500]} ... (ìƒëµ)

[ìš”êµ¬ì‚¬í•­]
1) "ì§„ë‹¨ ìš”ì•½ / ì„¼ì„œ íŠ¹ì´ì¹˜ / ê¶Œì¥ ì¡°ì¹˜ / í™•ë¥  ë¶„í¬" 4ë‹¨ë½
2) ì„¼ì„œ íŠ¹ì´ì¹˜ëŠ” ë¶„ìœ„ìˆ˜ ê¸°ì¤€(ìƒ/í•˜ìœ„ 10%)ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰
3) ê³¼ë„í•œ í™•ì • í‘œí˜„ ê¸ˆì§€, ì•ˆì „ ë¬¸êµ¬ í¬í•¨
"""
    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.2,
            messages=[
                {"role":"system","content":sys},
                {"role":"user","content":user}
            ],
        )
        return resp.choices[0].message.content
    except Exception:
        return template_report(row, pred, stats)

# -------------------------
# 4) UI
# -------------------------
tab_train, tab_infer, tab_batch = st.tabs(["â‘  í•™ìŠµ/í‰ê°€", "â‘¡ ë‹¨ê±´ ì§„ë‹¨", "â‘¢ ë°°ì¹˜ ì§„ë‹¨"])

with tab_train:
    st.subheader("AI4I 2020 ë°ì´í„° ì¤€ë¹„")
    colA, colB = st.columns([1,1])
    with colA:
        if st.button("UCIì—ì„œ AI4I ë°ì´í„° ë‚´ë ¤ë°›ê¸°"):
            with st.spinner("ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                df = download_ai4i()
                st.session_state["ai4i_raw"] = df
            st.success(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! rows={len(df):,}")
            st.dataframe(df.head())

    with colB:
        uploaded = st.file_uploader("ë˜ëŠ” CSV ì—…ë¡œë“œ(ì»¬ëŸ¼ëª… AI4I í¬ë§·)", type=["csv"])
        if uploaded is not None:
            df = pd.read_csv(uploaded)
            st.session_state["ai4i_raw"] = df
            st.success(f"ì—…ë¡œë“œ ì™„ë£Œ! rows={len(df):,}")
            st.dataframe(df.head())

    st.markdown("---")
    if st.button("ë°ì´í„° ê°€ê³µ â†’ í•™ìŠµ/ì €ì¥"):
        if "ai4i_raw" not in st.session_state:
            st.warning("ë¨¼ì € ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ì„¸ìš”.")
        else:
            with st.spinner("ê°€ê³µ/í•™ìŠµ ì¤‘..."):
                raw = st.session_state["ai4i_raw"]
                df = derive_failure_type(raw)
                pipe, report, cm, stats = fit_and_save_model(df)
            st.success("í•™ìŠµ ì™„ë£Œ & ëª¨ë¸ ì €ì¥!")
            st.code(report)
            st.write("í˜¼ë™í–‰ë ¬(label ìˆœì„œ):", TARGET_LABELS)
            st.dataframe(pd.DataFrame(cm, index=TARGET_LABELS, columns=TARGET_LABELS))

with tab_infer:
    st.subheader("ë‹¨ê±´ ì§„ë‹¨")
    pipe, stats = load_model_and_stats()
    if pipe is None:
        st.info("ë¨¼ì € â‘  íƒ­ì—ì„œ ëª¨ë¸ì„ í•™ìŠµ/ì €ì¥í•˜ì„¸ìš”.")
    else:
        # ì…ë ¥ ìœ„ì ¯ (ë²”ìœ„ëŠ” í•™ìŠµ ë°ì´í„° ë¶„ìœ„ìˆ˜ì— ë§ì¶° ì„¤ì •)
        q = stats["quantiles"]
        type_opt = st.selectbox("Type(ê°€ìƒ ì œí’ˆêµ°)", ["L","M","H"])
        air = st.number_input("Air temperature [K]", value=float(q["Air temperature [K]"]["q50"]))
        proc = st.number_input("Process temperature [K]", value=float(q["Process temperature [K]"]["q50"]))
        rpm = st.number_input("Rotational speed [rpm]", value=float(q["Rotational speed [rpm]"]["q50"]))
        torque = st.number_input("Torque [Nm]", value=float(q["Torque [Nm]"]["q50"]))
        wear = st.number_input("Tool wear [min]", value=float(q["Tool wear [min]"]["q50"]))

        row = {
            "Type": type_opt,
            "Air temperature [K]": air,
            "Process temperature [K]": proc,
            "Rotational speed [rpm]": rpm,
            "Torque [Nm]": torque,
            "Tool wear [min]": wear
        }

        if st.button("ì§„ë‹¨ ë³´ê³ ì„œ ìƒì„±", type="primary"):
            with st.spinner("ì¶”ë¡ /ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                pred = predict_row(pipe, row)
                report_txt = llm_report(row, pred, stats)
            st.markdown(report_txt)
            st.download_button("ë³´ê³ ì„œ .txt ì €ì¥", data=report_txt.encode("utf-8"),
                               file_name="diagnosis_report.txt", mime="text/plain")

with tab_batch:
    st.subheader("ë°°ì¹˜ ì§„ë‹¨ (CSV ì—…ë¡œë“œ)")
    pipe, stats = load_model_and_stats()
    if pipe is None:
        st.info("ë¨¼ì € â‘  íƒ­ì—ì„œ ëª¨ë¸ì„ í•™ìŠµ/ì €ì¥í•˜ì„¸ìš”.")
    else:
        up = st.file_uploader("ì„¼ì„œ ë¡œê·¸ CSV ì—…ë¡œë“œ (ì—´: Type, Air..., Process..., Rotational..., Torque..., Tool wear...)", type=["csv"], key="batch")
        if up is not None:
            df_in = pd.read_csv(up)
            st.write(f"ì…ë ¥ ìƒ˜í”Œ (rows={len(df_in):,})")
            st.dataframe(df_in.head())

            if st.button("ì¼ê´„ ì§„ë‹¨ ì‹¤í–‰"):
                with st.spinner("ë°°ì¹˜ ì¶”ë¡  ì¤‘..."):
                    preds = pipe.predict_proba(df_in)
                    classes = list(pipe.classes_)
                    labels = np.array(classes)[preds.argmax(1)]
                    confid = preds.max(1)
                    out = df_in.copy()
                    out["pred_label"] = labels
                    out["pred_proba"] = confid

                    # ê°„ë‹¨í•œ í…œí”Œë¦¿ ë³´ê³ ì„œë„ ê°™ì´ ì»¬ëŸ¼ìœ¼ë¡œ ìƒì„±(ì§§ê²Œ)
                    short_reports = []
                    for i, row in out.iterrows():
                        rdict = {
                            "Type": row["Type"],
                            "Air temperature [K]": row["Air temperature [K]"],
                            "Process temperature [K]": row["Process temperature [K]"],
                            "Rotational speed [rpm]": row["Rotational speed [rpm]"],
                            "Torque [Nm]": row["Torque [Nm]"],
                            "Tool wear [min]": row["Tool wear [min]"],
                        }
                        pr = PredictionResult(row["pred_label"], row["pred_proba"],
                                              {c: float(p) for c, p in zip(classes, preds[i])})
                        short_reports.append(template_report(rdict, pr, stats).replace("\n", " ")[:500])
                    out["short_report"] = short_reports

                st.success("ì™„ë£Œ!")
                st.dataframe(out.head())
                # ë‹¤ìš´ë¡œë“œ
                buffer = io.StringIO()
                out.to_csv(buffer, index=False)
                st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", buffer.getvalue().encode("utf-8"),
                                   file_name="batch_diagnosis.csv", mime="text/csv")

st.caption("â€» ë³¸ ë„êµ¬ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ ì„¤ë¹„ ì˜ì‚¬ê²°ì •ì€ ì „ë¬¸ê°€ ì ê²€ê³¼ ë³‘í–‰í•˜ì„¸ìš”.")
